{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e890c00-6a42-48c6-a1ba-5e3d0450037f",
   "metadata": {},
   "source": [
    "# Robot functions (to be completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "340ff3f5-d340-4d1f-bbc5-75dc5b21d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install math3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e9bb0b-3bbc-4c02-b0cc-3ca56aba48d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urx\n",
    "import robotiq_gripper\n",
    "\n",
    "# ip1 = \"192.168.2.207\"   #ip of the UR robot to connect\n",
    "\n",
    "# ip2 = \"\"   #???????\n",
    "\n",
    "# gripper_1 = robotiq_gripper.RobotiqGripper()  # initialize the gripper\n",
    "# gripper_2 = robotiq_gripper.RobotiqGripper()   #???????\n",
    "# print(\"Connecting to grippers...\")\n",
    "\n",
    "\n",
    "# gripper_1.connect(ip1, 63352)                  # connect to the gripper\n",
    "                                           \n",
    "# robot_1 = urx.Robot(ip1, use_rt=True)            # connect to the UR robot\n",
    "\n",
    "\n",
    "# gripper_2.connect(ip2, 63352)                  # connect to the gripper\n",
    "                                           \n",
    "# robot_2 = urx.Robot(ip2, use_rt=True)            # connect to the UR robot\n",
    "\n",
    "\n",
    "\n",
    "# def move_top(robot_id, gripper_id , object_position):  \n",
    "#     return \"\"\n",
    "\n",
    "# def gripper_open(robot_id, gripper_id):\n",
    "#     gripper_id.move_and_wait_for_pos(0,100,100)\n",
    "\n",
    "\n",
    "\n",
    "############################# functions used in prompting  \n",
    "\n",
    "def move_to_object(robot_id, gripper_id, object_position): # to move to the position of an object\n",
    "    print(\" move_to_object(robot_id, gripper_id, object_position) \")\n",
    "    return \" move_to_object(robot_id, gripper_id, object_position) \" # for testing\n",
    "\n",
    "\n",
    "def grasp_object(robot_id, gripper_id, object_position):  # to grasp an object\n",
    "    print(\" grasp_object(robot_id, gripper_id, object_position)\" )\n",
    "    return \" grasp_object(robot_id, gripper_id, object_position) \" # for testing\n",
    "\n",
    "def connect(robot_id, gripper_id, object_1_position, object_2_position): # connect a part to another\n",
    "    print(\" connect(robot_id, gripper_id, object_1_position, object_2_position)\")\n",
    "    return \" connect(robot_id, gripper_id, object_1_position, object_2_position)\" # for testing\n",
    "\n",
    "def hold_object(robot_id, gripper_id, object_position): # To apply a forcce on the base to avoid it moving\n",
    "    print(\" hold_object(robot_id, gripper_id, object_position) \" )\n",
    "    return \" hold_object(robot_id, gripper_id, object_position) \" # for testing\n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "\n",
    "\n",
    "def move_to_object_wrapper(state):  #inputs = {\"messages\": [steps_list[0],'Robot1_base_holder', 'gripper1', \"{'x': -25\", \"'y': 0\", \"'alpha': 0}\"]}\n",
    "    return  move_to_object()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "703afc2b-d2e0-4f43-8d7e-e85b41682451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langgraph\n",
    "# ! pip install langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0cf80c-f4a9-43ea-8ea7-5cb55811b071",
   "metadata": {},
   "source": [
    "## JSON file details extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d7b918-695b-4e8f-b28f-47707792a4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af767e53-d8dc-47ba-9f67-b281543160ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All output has been saved to output.txt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "class AssemblyEnvironment:\n",
    "    def __init__(self, json_file):\n",
    "        with open(json_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        self.base = data['assembly']['base']\n",
    "        self.base_num_pins=len(self.base[\"pins\"])\n",
    "        self.parts = data['assembly']['parts']\n",
    "        self.num_parts = len(self.parts)\n",
    "        self.base_position = data['assembly']['base']['position']\n",
    "\n",
    "        # Dynamically create pin attributes\n",
    "        for i in range(len(self.base[\"pins\"])):\n",
    "            pin_name = f\"base_pin_{i + 1}\"  # Create dynamic pin names\n",
    "            setattr(self, pin_name, self.base[\"pins\"][i])\n",
    "        \n",
    "        # Extract part details dynamically\n",
    "        for i, part in enumerate(self.parts):\n",
    "            part_id = part[\"id\"]\n",
    "            setattr(self, f\"{part_id}_position\", part[\"position\"])\n",
    "            setattr(self, f\"{part_id}_target_position\", part[\"target_position\"])\n",
    "            setattr(self, f\"{part_id}_mounting_hole\", part[\"mounting_hole\"])\n",
    "            setattr(self, f\"{part_id}_grip_pin\", part[\"grip_pin\"])\n",
    "\n",
    "        self.assembly_prompt  = lambda user_query: f\"\"\" \n",
    "You are an AI agent which task is to provide a detail plan for fully assembling an object of {self.num_parts + 1 } different components. \n",
    "The object has a base with { self.base_num_pins } pins where the  {self.num_parts} others parts which all contains amounting hole have to be mounted.\n",
    "The object have to be assembled by two robot (Robot1_base_holder ,Robot2_assembler) manipulator each equipped with a gripper (gripper1, gripper2)and \n",
    "your goal is to provide a deatailed plan on how the to robots have to collaborate togother to solve the assembly task by strictly using \n",
    "the following functions to control the motions of the two robots: move_to_object(robot_id, gripper_id, object_position), \n",
    "grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position), \n",
    "connect(robot_id, gripper_id, object_1_position, object_2_position).\n",
    "\n",
    "In order to answer use the following template:\n",
    "\n",
    "START OF PLAN\n",
    " step 1 - [CHOICE:  Robot1_base_holder,Robot2_assembler]  should move to the position of the base using the function [CHOICE: move_to_object(robot_id, gripper_id, object_position), \n",
    "   grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position)]\n",
    " step 2 - [CHOICE:  Robot1_base_holder,Robot2_assembler]  should hold the base using the function [CHOICE: move_to_object(robot_id, gripper_id, object_position), \n",
    "grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position), \n",
    "connect(robot_id, gripper_id, object_1_position, object_2_position)]\n",
    " step 3 - [CHOICE:  Robot1_base_holder,Robot2_assembler]  shoul move to the positon of [CHOICE: part_1, part_2, ....] with the function  [CHOICE: move_to_object(robot_id, gripper_id, object_position), \n",
    "grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position), connect(robot_id, gripper_id, object_1_position, object_2_position)]\n",
    " step 4 - [CHOICE:  Robot1_base_holder,Robot2_assembler]  should move grasp [CHOICE: part_1, part_2, ....] with the function  [CHOICE: move_to_object(robot_id, gripper_id, object_position), \n",
    "grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position), \n",
    "connect(robot_id, gripper_id, object_1_position, object_2_position)]\n",
    " step 5 - [CHOICE:  Robot1_base_holder,Robot2_assembler]  should connect  [CHOICE: part_1, part_2, ....] to the pin  [CHOICE: pin_1, pin_2, ....] on the base with the function\n",
    "[CHOICE: move_to_object(robot_id, gripper_id, object_position), grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position), \n",
    "connect(robot_id, gripper_id, object_1_position, object_2_position)]\n",
    " step 6 - .....\n",
    "END OF PLAN\n",
    "\n",
    "\n",
    "Rules:\n",
    "1. your answer should explicitly start with 'START OF PLAN' and end it with 'END OF PLAN' .\n",
    "2. When you see phrases like [CHOICE: choice1, choice2, ...], you should replace the entire phrase with only one of the choices listed.\n",
    "3. only Robot1_base_holder should hold the base for satability reasons when Robot2_assembler is doing the assembly task\n",
    "\n",
    "\n",
    "Example output:\n",
    "START OF PLAN\n",
    " 1 - Robot1_base_holder should move to the position of the base using the function move_to_object(robot1_base_holder, gripper1, base_position), \n",
    " 2  .....\n",
    "END OF PLAN\n",
    "\n",
    "\n",
    "Now here is the user given task : {user_query}\n",
    "\"\"\"    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Redirect stdout to a file\n",
    "    original_stdout = sys.stdout  # Save a reference to the original standard output\n",
    "\n",
    "    with open('output.txt', 'w') as f:\n",
    "        sys.stdout = f  # Change the standard output to the file we created.\n",
    "\n",
    "        # Create an instance of AssemblyEnvironment by providing the path to the JSON file\n",
    "        assembly_env = AssemblyEnvironment('assembly_details.JSON')\n",
    "\n",
    "        \n",
    "        print(\"On The Base:\")\n",
    "        \n",
    "        # Print the base and pins to verify\n",
    "        for pin in assembly_env.base[\"pins\"]:\n",
    "            pin_id = pin[\"id\"]\n",
    "            pin_position = pin[\"position\"]\n",
    "            print(f\"Pin {pin_id} Position on the base:\", pin_position)  # Print pin position\n",
    "\n",
    "\n",
    "        print(\"\\n\")\n",
    "        print(f\"The {assembly_env.num_parts} assembly parts:\")\n",
    "        \n",
    "        # Accessing dynamic part attributes with detailed descriptions\n",
    "        for part in assembly_env.parts:\n",
    "            part_id = part[\"id\"]\n",
    "            print(f\"Part {part_id}:\")\n",
    "            # print(f\"{part_id} Position:\", getattr(assembly_env, f\"{part_id}_position\"))  # Position of the part\n",
    "            print(f\"{part_id} Target Position:\", getattr(assembly_env, f\"{part_id}_target_position\"))  # Target position of the part\n",
    "            print(f\"{part_id} Mounting Hole:\", getattr(assembly_env, f\"{part_id}_mounting_hole\"))  # Mounting hole details of the part\n",
    "            print(f\"{part_id} Grip Pin:\", getattr(assembly_env, f\"{part_id}_grip_pin\"))  # Grip pin position of the part\n",
    "            print(\"-----------\")\n",
    "            \n",
    "        sys.stdout = original_stdout  # Reset the standard output to its original value\n",
    "\n",
    "print(\"All output has been saved to output.txt\")\n",
    "# print(assembly_env.assembly_prompt(\"hollllllllllllllllllllllllllla\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36277eeb-837f-4eec-a76f-6bfb4087f92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7590d903-a371-4279-b34f-c45cbc41b791",
   "metadata": {},
   "source": [
    "## RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "192a7dfd-23a6-4ab9-9626-70a01d13712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-community\n",
    "# !pip install sentence_transformers\n",
    "# !pip install --upgrade chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0457b567-1d6c-4e08-8027-704996cc271c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koffi/anaconda3/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'output.txt'}, page_content=\"part_2 Mounting Hole: {'id': 2, 'position': {'x': 0, 'y': 0, 'alpha': 0}}\")]\n"
     ]
    }
   ],
   "source": [
    "################################################################ RAG\n",
    "\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "### Reading the txt files from source directory\n",
    "\n",
    "loader = DirectoryLoader('./', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "### Creating Chunks using RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len\n",
    ")\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n",
    "doc_strings = [doc.page_content for doc in new_docs]\n",
    "\n",
    "###  BGE Embddings\n",
    "\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")\n",
    "\n",
    "### Creating Retriever using Vector DB\n",
    "\n",
    "db = Chroma.from_documents(new_docs, embeddings)\n",
    "# retriever = db.as_retriever(search_kwargs={\"k\": 4})\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################### testing RAG\n",
    "query = \"what is the Mounting Hole of part 2\"\n",
    "docs = retriever.invoke(query)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9570a578-a80e-4492-bb15-da0d735f4780",
   "metadata": {},
   "source": [
    "## Building agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa163e3-0e23-49cf-9eb5-cff62b2995c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "import operator\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import functools\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03931947-ac34-4abe-838e-082a16564f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e986c4ec-d376-4e47-b10f-9c0ea11d9991",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Now you can access your environment variables using os.environ\n",
    "os.environ['OPENAI_API_KEY'] = ''\n",
    "# os.environ['TAVILY_API_KEY'] = os.environ.get(\"TAVILY_API_KEY\")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "# llm = ChatOpenAI(model=\"gpt-4-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b0eed6-d972-4075-abe9-7b178f44aaf6",
   "metadata": {},
   "source": [
    "## Graph 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49f224b8-87ca-433f-9ea0-8a62c4df2ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_plan(plan_text):\n",
    "    # Split the input text into lines\n",
    "    lines = plan_text.strip().split('\\n')\n",
    "    \n",
    "    # Initialize an empty list to hold the formatted output\n",
    "    formatted_lines = []\n",
    "    \n",
    "    # Flag to indicate if we are within the plan section\n",
    "    in_plan = False\n",
    "    \n",
    "    # Iterate over the lines\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line == \"START OF PLAN\":\n",
    "            in_plan = True\n",
    "            continue\n",
    "        elif line == \"END OF PLAN\":\n",
    "            break\n",
    "        \n",
    "        # If we are in the plan section, format the line\n",
    "        if in_plan and line:\n",
    "            formatted_lines.append(f'\"{line}\"')\n",
    "    \n",
    "    # Return the formatted lines joined by newline characters\n",
    "    return '\\n'.join(formatted_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc033ac1-2622-4b15-bd60-055f34215ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_plan_step1(state):\n",
    "    print('-> ...Plan Generation 1... ->')\n",
    "    messages = state['messages']\n",
    "    user_query = messages[-1]   ## Fetching the user question\n",
    "    complete_query = assembly_env.assembly_prompt( user_query) # to do\n",
    "    response = llm.invoke(complete_query)\n",
    "    state['messages'].append(response.content) # appending LLM call response to the AgentState\n",
    "    print('-> ...Plan Generation 1 Done... ->')\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def generate_plan_step2(state, filename = 'output.txt' ):\n",
    "    print('-> ...Plan Generation 2... ->')\n",
    "    \n",
    "    messages = state['messages']\n",
    "    plan = messages[-1] ## Fetching the user question\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        context = file.read() #to check later \n",
    "    \n",
    "    question = \"Now here is the plan to fill up: \\n \" + plan\n",
    "    # print('Question:',question)\n",
    "\n",
    "    template_format = lambda ctext, quest : f\"\"\"You will recieve a plan generated by an AI agent which contain a list of step that two robot manipulators \n",
    "have to follow in order to perform a user given task. The plan contain some functions and your goal is to replace the arguments \n",
    "of the function by their real values. All the reals variables values can be find in the following retrieved context:\\n\n",
    "{ctext}\n",
    "\n",
    "Example: \n",
    "If the plan is like:\n",
    "step 1 - Robot1_base_holder should move to the position of the base using the function move_to_object(Robot1_base_holder, gripper1, base_position)\n",
    "then your response should look like:\n",
    "step 1 - Robot1_base_holder should move to the position of the base using the function move_to_object(Robot1_base_holder, gripper1, [-25, 0, 0])\n",
    "\n",
    "Question: {quest}\n",
    "    \"\"\"\n",
    "    template = template_format(context,question)\n",
    "    print('template:',template)\n",
    "    # prompt = ChatPromptTemplate.from_template(template)\n",
    "    # print(\"debug\")\n",
    "    # retrieval_chain = (\n",
    "    #     {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    #     | prompt\n",
    "    #     | llm\n",
    "    #     | StrOutputParser()\n",
    "    #     )\n",
    "    # result = retrieval_chain.invoke(question)\n",
    "\n",
    "    response = llm.invoke(template)\n",
    "    # clean_response = transform_plan(response.content)\n",
    "    # # clean_response = response\n",
    "    state[\"messages\"] = []\n",
    "    # state['messages'].append(clean_response) # appending LLM call response to the AgentState\n",
    "    state['messages'].append(response.content) # appending LLM call response to the AgentState\n",
    "    print('-> ...Plan Generation 2 Done... ->')\n",
    "    return state\n",
    "    \n",
    "    # return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cad50720-1789-4995-a897-c852385dca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Langchain graph\n",
    "\n",
    "# assign AgentState as an empty dict\n",
    "AgentState = {}\n",
    "\n",
    "# messages key will be assigned as an empty array. We will append new messages as we pass along nodes. \n",
    "AgentState[\"messages\"] = []\n",
    "\n",
    "\n",
    "workflow1 = Graph()\n",
    "\n",
    "# workflow.add_node(\"Agent\", function_1)\n",
    "# workflow.add_node(\"tool\", function_2)\n",
    "# workflow1 = Graph().add_edge('Agent', 'tool')\n",
    "workflow1.add_node(\"generate_plan1\", generate_plan_step1)\n",
    "workflow1.add_node(\"generate_plan2\", generate_plan_step2)\n",
    "workflow1.add_edge('generate_plan1', 'generate_plan2')\n",
    "\n",
    "workflow1.set_entry_point(\"generate_plan1\")\n",
    "workflow1.set_finish_point(\"generate_plan2\")\n",
    "\n",
    "app1 = workflow1.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d22a3e72-6c70-4fc2-b1d0-fb0428de6159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> ...Plan Generation 1... ->\n",
      "-> ...Plan Generation 1 Done... ->\n",
      "-> ...Plan Generation 2... ->\n",
      "template: You will recieve a plan generated by an AI agent which contain a list of step that two robot manipulators \n",
      "have to follow in order to perform a user given task. The plan contain some functions and your goal is to replace the arguments \n",
      "of the function by their real values. All the reals variables values can be find in the following retrieved context:\n",
      "\n",
      "On The Base:\n",
      "Pin 1 Position on the base: {'x': -25, 'y': 0, 'alpha': 0}\n",
      "Pin 2 Position on the base: {'x': 25, 'y': 0, 'alpha': 0}\n",
      "\n",
      "\n",
      "The 2 assembly parts:\n",
      "Part part_1:\n",
      "part_1 Target Position: {'x': -25, 'y': 0, 'alpha': 0}\n",
      "part_1 Mounting Hole: {'id': 1, 'position': {'x': 0, 'y': 0, 'alpha': 0}}\n",
      "part_1 Grip Pin: {'position': {'x': -40, 'y': 15, 'alpha': 0}}\n",
      "-----------\n",
      "Part part_2:\n",
      "part_2 Target Position: {'x': 25, 'y': 0, 'alpha': 0}\n",
      "part_2 Mounting Hole: {'id': 2, 'position': {'x': 0, 'y': 0, 'alpha': 0}}\n",
      "part_2 Grip Pin: {'position': {'x': 40, 'y': 15, 'alpha': 0}}\n",
      "-----------\n",
      "\n",
      "\n",
      "Question: Now here is the plan to fill up: \n",
      " START OF PLAN\n",
      " step 1 - Robot1_base_holder should move to the position of the base using the function move_to_object(Robot1_base_holder, gripper1, base_position)\n",
      " step 2 - Robot1_base_holder should hold the base using the function grasp_object(Robot1_base_holder, gripper1, base_position)\n",
      " step 3 - Robot2_assembler should move to the position of part_1 using the function move_to_object(Robot2_assembler, gripper2, part_1_position)\n",
      " step 4 - Robot2_assembler should grasp part_1 using the function grasp_object(Robot2_assembler, gripper2, part_1_position)\n",
      " step 5 - Robot2_assembler should connect part_1 to pin_1 on the base using the function connect(Robot2_assembler, gripper2, part_1_position, pin_1_position)\n",
      " step 6 - Robot2_assembler should move to the position of part_2 using the function move_to_object(Robot2_assembler, gripper2, part_2_position)\n",
      " step 7 - Robot2_assembler should grasp part_2 using the function grasp_object(Robot2_assembler, gripper2, part_2_position)\n",
      " step 8 - Robot2_assembler should connect part_2 to pin_2 on the base using the function connect(Robot2_assembler, gripper2, part_2_position, pin_2_position)\n",
      "END OF PLAN\n",
      "    \n",
      "-> ...Plan Generation 2 Done... ->\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [\"assemble a gripper of one base and two parts for me\"]}\n",
    "out =  app1.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee5e5469-42a5-402b-8e55-f24fb88ef0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"START OF PLAN\\n step 1 - Robot1_base_holder should move to the position of the base using the function move_to_object(Robot1_base_holder, gripper1, {'x': -25, 'y': 0, 'alpha': 0})\\n step 2 - Robot1_base_holder should hold the base using the function grasp_object(Robot1_base_holder, gripper1, {'x': -25, 'y': 0, 'alpha': 0})\\n step 3 - Robot2_assembler should move to the position of part_1 using the function move_to_object(Robot2_assembler, gripper2, {'x': -25, 'y': 0, 'alpha': 0})\\n step 4 - Robot2_assembler should grasp part_1 using the function grasp_object(Robot2_assembler, gripper2, {'x': -25, 'y': 0, 'alpha': 0})\\n step 5 - Robot2_assembler should connect part_1 to pin_1 on the base using the function connect(Robot2_assembler, gripper2, {'x': -25, 'y': 0, 'alpha': 0}, {'x': -25, 'y': 0, 'alpha': 0})\\n step 6 - Robot2_assembler should move to the position of part_2 using the function move_to_object(Robot2_assembler, gripper2, {'x': 25, 'y': 0, 'alpha': 0})\\n step 7 - Robot2_assembler should grasp part_2 using the function grasp_object(Robot2_assembler, gripper2, {'x': 25, 'y': 0, 'alpha': 0})\\n step 8 - Robot2_assembler should connect part_2 to pin_2 on the base using the function connect(Robot2_assembler, gripper2, {'x': 25, 'y': 0, 'alpha': 0}, {'x': 25, 'y': 0, 'alpha': 0})\\nEND OF PLAN\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73595a22-a688-4145-9521-13ecb0871c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4ea729-7415-47c2-8945-5a5fb8b96018",
   "metadata": {},
   "source": [
    "## Graph 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d795906f-1410-4dc2-b9b7-2b06e9079418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot1_base_holder should move to the position of the base using the function move_to_object(Robot1_base_holder, gripper1, {'x': -25, 'y': 0, 'alpha': 0})\n",
      "Robot1_base_holder should hold the base using the function grasp_object(Robot1_base_holder, gripper1, {'x': -25, 'y': 0, 'alpha': 0})\n",
      "Robot2_assembler should move to the position of part_1 using the function move_to_object(Robot2_assembler, gripper2, {'x': -25, 'y': 0, 'alpha': 0})\n",
      "Robot2_assembler should grasp part_1 using the function grasp_object(Robot2_assembler, gripper2, {'x': -25, 'y': 0, 'alpha': 0})\n",
      "Robot2_assembler should connect part_1 to pin_1 on the base using the function connect(Robot2_assembler, gripper2, {'x': -25, 'y': 0, 'alpha': 0}, {'x': -25, 'y': 0, 'alpha': 0})\n",
      "Robot2_assembler should move to the position of part_2 using the function move_to_object(Robot2_assembler, gripper2, {'x': 25, 'y': 0, 'alpha': 0})\n",
      "Robot2_assembler should grasp part_2 using the function grasp_object(Robot2_assembler, gripper2, {'x': 25, 'y': 0, 'alpha': 0})\n",
      "Robot2_assembler should connect part_2 to pin_2 on the base using the function connect(Robot2_assembler, gripper2, {'x': 25, 'y': 0, 'alpha': 0}, {'x': 25, 'y': 0, 'alpha': 0})\n"
     ]
    }
   ],
   "source": [
    "def extract_steps(plan_text):\n",
    "    # Split the input text into lines\n",
    "    lines = plan_text.splitlines()\n",
    "    \n",
    "    # Initialize an empty list to hold the steps\n",
    "    steps = []\n",
    "    \n",
    "    # Flag to check if we are within the plan\n",
    "    in_plan = False\n",
    "    \n",
    "    for line in lines:\n",
    "        # Check for the start and end of the plan\n",
    "        if \"START OF PLAN\" in line:\n",
    "            in_plan = True\n",
    "            continue\n",
    "        elif \"END OF PLAN\" in line:\n",
    "            break\n",
    "        \n",
    "        # If we are within the plan, extract the step\n",
    "        if in_plan and line.strip():\n",
    "            # Extract the step description\n",
    "            step = line.split(\" - \", 1)[1].strip() if \" - \" in line else line.strip()\n",
    "            steps.append(step)\n",
    "    \n",
    "    return steps\n",
    "\n",
    "\n",
    "# Extracting steps\n",
    "steps_list = extract_steps(out['messages'][0]) \n",
    "for i in steps_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54761dd4-8298-4bb0-8383-2dc1bffdb679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Robot1_base_holder should move to the position of the base using the function move_to_object(Robot1_base_holder, gripper1, {'x': -25, 'y': 0, 'alpha': 0})\",\n",
       " \"Robot1_base_holder should hold the base using the function grasp_object(Robot1_base_holder, gripper1, {'x': -25, 'y': 0, 'alpha': 0})\",\n",
       " \"Robot2_assembler should move to the position of part_1 using the function move_to_object(Robot2_assembler, gripper2, {'x': -25, 'y': 0, 'alpha': 0})\",\n",
       " \"Robot2_assembler should grasp part_1 using the function grasp_object(Robot2_assembler, gripper2, {'x': -25, 'y': 0, 'alpha': 0})\",\n",
       " \"Robot2_assembler should connect part_1 to pin_1 on the base using the function connect(Robot2_assembler, gripper2, {'x': -25, 'y': 0, 'alpha': 0}, {'x': -25, 'y': 0, 'alpha': 0})\",\n",
       " \"Robot2_assembler should move to the position of part_2 using the function move_to_object(Robot2_assembler, gripper2, {'x': 25, 'y': 0, 'alpha': 0})\",\n",
       " \"Robot2_assembler should grasp part_2 using the function grasp_object(Robot2_assembler, gripper2, {'x': 25, 'y': 0, 'alpha': 0})\",\n",
       " \"Robot2_assembler should connect part_2 to pin_2 on the base using the function connect(Robot2_assembler, gripper2, {'x': 25, 'y': 0, 'alpha': 0}, {'x': 25, 'y': 0, 'alpha': 0})\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "075f3707-2150-45ce-b276-c3b7b9ecd848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel , Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "class TopicSelectionParser(BaseModel):\n",
    "    Topic: str = Field(description='Selected Topic')\n",
    "    #Reasoning: str = Field(description='Reasoning behind topic selection')\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=TopicSelectionParser)\n",
    "\n",
    "\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bef60e3a-0cdd-4db2-ac69-bb3c9166fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input type: 1. **step 1** - Robot1_base_holder should move to the position of the base using the \n",
    "# function move_to_object(robot1_base_holder, gripper1, {\\'x\\': 0, \\'y\\': 0, \\'alpha\\': 0})\n",
    "\n",
    "def clf_functions(state):\n",
    "    print('-> Calling classifier ->')\n",
    "    messages = state['messages']\n",
    "    # question = messages[-1]   ## Fetching the user question\n",
    "    question = messages[0]\n",
    "    \n",
    "    templete = \"\"\" Your task is choose the right function that have to be used based on the input query. \n",
    "        Only output the function among: [move_to_object ,grasp_object , connect, hold_object ]. \n",
    "        Don't include reasoning. \n",
    "        Following is the input query:  {question}\n",
    "        {format_instructions} \"\"\"\n",
    "    prompt = PromptTemplate(template=templete,\n",
    "                                    input_variables=[question],\n",
    "                                    partial_variables={\n",
    "                                        \"format_instructions\" : parser.get_format_instructions()                                    }\n",
    "                                    )\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    response = chain.invoke({\"question\":question,\"format_instructions\" : parser.get_format_instructions() })\n",
    "\n",
    "    print(response)\n",
    "\n",
    "    state[\"messages\"][0] = response.Topic\n",
    "\n",
    "    # return {\"messages\": [response.Topic]}\n",
    "    return state\n",
    "\n",
    "\n",
    "def router(state):\n",
    "    print('-> Router ->')\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[0]\n",
    "    print(last_message)\n",
    "    if 'move_to_object' in last_message:\n",
    "        return 'move_to_object Call'\n",
    "    elif 'grasp_object' in last_message:\n",
    "        return 'grasp_object Call'\n",
    "    elif 'connect' in last_message:\n",
    "        return 'connect Call'\n",
    "    elif 'hold_object' in last_message:\n",
    "        return 'hold_object Call'\n",
    "    else:\n",
    "        return 'Sorry Sorry Sorry'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from langgraph.graph import StateGraph,END\n",
    "\n",
    "graph = StateGraph(AgentState) ### StateGraph with AgentState\n",
    "\n",
    "graph.add_node(\"move_to_object\", move_to_object)\n",
    "graph.add_node(\"grasp_object\", grasp_object)\n",
    "graph.add_node(\"connect\", connect)\n",
    "graph.add_node(\"hold_object\", hold_object)\n",
    "graph.add_node(\"clf functions\", clf_functions)\n",
    "\n",
    "graph.set_entry_point(\"clf functions\")\n",
    "\n",
    "\n",
    "# conditional edges are controlled by our router\n",
    "graph.add_conditional_edges(\n",
    "    \"clf functions\",\n",
    "    router,\n",
    "    {\n",
    "        \"move_to_object Call\": \"move_to_object\",\n",
    "        \"grasp_object Call\": \"grasp_object\",\n",
    "        \"connect Call\":\"connect\",\n",
    "        \"hold_object Cal\":\"hold_object\",\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "graph.add_edge(\"move_to_object\", END)\n",
    "graph.add_edge(\"connect\", END)\n",
    "graph.add_edge(\"grasp_object\", END)\n",
    "graph.add_edge(\"hold_object\", END)\n",
    "\n",
    "app2 = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82128ace-8f3c-46ed-890f-78e49d840795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Calling classifier ->\n",
      "Topic='move_to_object'\n",
      "-> Router ->\n",
      "move_to_object\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "move_to_object() missing 2 required positional arguments: 'gripper_id' and 'object_position'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [steps_list[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRobot1_base_holder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgripper1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: -25\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: 0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: 0}\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m----> 2\u001b[0m out \u001b[38;5;241m=\u001b[39m app2\u001b[38;5;241m.\u001b[39minvoke(inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1617\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1616\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1617\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   1618\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1619\u001b[0m     config,\n\u001b[1;32m   1620\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   1621\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   1622\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   1623\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   1624\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   1625\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1626\u001b[0m ):\n\u001b[1;32m   1627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1628\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1303\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1300\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m _panic_or_proceed(all_futures, loop\u001b[38;5;241m.\u001b[39mstep)\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1733\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[0;34m(futs, step, timeout_exc_cls)\u001b[0m\n\u001b[1;32m   1731\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m   1732\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m-> 1733\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[1;32m   1736\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[1;32m   1738\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langgraph/pregel/executor.py:59\u001b[0m, in \u001b[0;36mBackgroundExecutor.done\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdone\u001b[39m(\u001b[38;5;28mself\u001b[39m, task: concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFuture) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m         task\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m GraphInterrupt:\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mpop(task)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langgraph/pregel/retry.py:26\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     24\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39minvoke(task\u001b[38;5;241m.\u001b[39minput, task\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langchain_core/runnables/base.py:2876\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2874\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m   2875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2876\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2877\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2878\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langgraph/utils.py:102\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accepts_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[1;32m    101\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m--> 102\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[0;31mTypeError\u001b[0m: move_to_object() missing 2 required positional arguments: 'gripper_id' and 'object_position'"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [steps_list[0],'Robot1_base_holder', 'gripper1', \"{'x': -25\", \"'y': 0\", \"'alpha': 0}\"]}\n",
    "out = app2.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19d5b27a-5338-4296-bb76-cd579c810e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66fe2a28-e529-4aee-ad93-3d6fac531abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [\"Robot1_base_holder should move to the position of the base using the function move_to_object(Robot1_base_holder, gripper1, {'x': -25, 'y': 0, 'alpha': 0})\"]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5b7a7e-e1ac-4e34-b01c-a7f0f6f5d460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf01fb-c9d1-44e2-9bbe-67c349f18b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e6785-77ea-4ead-a23c-e5208dfc9ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0492d537-e6f8-43a1-97db-77585d6edaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865203a6-62a1-401a-9515-60f40ec1fdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca5d75d-4533-4e93-8711-f29c729c3c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b6d21-14b8-4368-bba6-fc20c3eabcd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b684cda-2e7a-4d17-afa5-e83c78767016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78437fe-7ba5-46ac-b4a5-ebb47185f1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f421f841-5620-44f3-a84b-a440a4c7a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def router(state):\n",
    "#     print('-> Router ->')\n",
    "    \n",
    "#     messages = state[\"messages\"]\n",
    "#     last_message = messages[-1]\n",
    "#     print(last_message)\n",
    "#     if 'Japan' in last_message or 'Sports' in last_message:\n",
    "#         return 'RAG Call'\n",
    "#     else:\n",
    "#         return 'LLM Call'\n",
    "\n",
    "# from langgraph.graph import StateGraph,END\n",
    "\n",
    "# graph = StateGraph(AgentState) ### StateGraph with AgentState\n",
    "\n",
    "# graph.add_node(\"agent\", function_1)\n",
    "# graph.add_node(\"RAG\", function_2)\n",
    "# graph.add_node(\"LLM\", function_3)\n",
    "\n",
    "# graph.set_entry_point(\"agent\")\n",
    "\n",
    "\n",
    "# # conditional edges are controlled by our router\n",
    "# graph.add_conditional_edges(\n",
    "#     start_key=\"agent\",  # where in graph to start\n",
    "#     condition=router,  # function to determine which node is called\n",
    "#     conditional_edge_mapping={\n",
    "#         \"RAG Call\": \"RAG\",\n",
    "#         \"LLM Call\": \"LLM\",\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# graph.add_edge(\"RAG\", END)\n",
    "# graph.add_edge(\"LLM\", END)\n",
    "\n",
    "# app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15b6b48-44cd-4f9d-9811-df4863008022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = {\"messages\": [\"Tell me about Japan's Industrial Growth\"]}\n",
    "# out = app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc0751a-cf33-480e-9b7f-a26821c9a872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26938ff6-da15-41dc-adb5-8c29e4bcf5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c69c70-3e10-4257-9642-eea3c63512eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be81e1-9693-4d02-87a4-7146eb607444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209dd75f-b0f5-4f83-99f1-4e1046475f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def determine_call_type(last_message):\n",
    "#     if 'move_to_object' in last_message:\n",
    "#         return 'RAG Call'\n",
    "#     elif 'grasp_object' in last_message:\n",
    "#         return 'RAG Call'\n",
    "#     elif 'connect' in last_message:\n",
    "#         return 'RAG Call'\n",
    "#     elif 'hold_object' in last_message:\n",
    "#         return 'RAG Call'\n",
    "#     else:\n",
    "#         return 'LLM Call'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bcdd25-cd75-4d06-acaa-b6b44f120185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea78983-8795-4f9c-b91a-372e2b6ca59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eab127-cdb7-4795-8030-9b0a374a38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def move_to_object(robot_id, gripper_id, object_position): # to move to the position of an object\n",
    "#     return \" move_to_object(robot_id, gripper_id, object_position) \" # for testing\n",
    "\n",
    "\n",
    "# def grasp_object(robot_id, gripper_id, object_position):  # to grasp an object\n",
    "#     return \" grasp_object(robot_id, gripper_id, object_position) \" # for testing\n",
    "\n",
    "# def connect(robot_id, gripper_id, object_1_position, object_2_position): # connect a part to another\n",
    "#     return \" connect(robot_id, gripper_id, object_1_position, object_2_position)\" # for testing\n",
    "\n",
    "# def hold_object(robot_id, gripper_id, object_position): # To apply a forcce on the base to avoid it moving\n",
    "#     return \" hold_object(robot_id, gripper_id, object_position) \" # for testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
