{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e890c00-6a42-48c6-a1ba-5e3d0450037f",
   "metadata": {},
   "source": [
    "# Robot functions (to be completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "340ff3f5-d340-4d1f-bbc5-75dc5b21d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install math3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e9bb0b-3bbc-4c02-b0cc-3ca56aba48d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urx\n",
    "import robotiq_gripper\n",
    "\n",
    "# ip1 = \"192.168.2.207\"   #ip of the UR robot to connect\n",
    "\n",
    "# ip2 = \"\"   #???????\n",
    "\n",
    "# gripper_1 = robotiq_gripper.RobotiqGripper()  # initialize the gripper\n",
    "# gripper_2 = robotiq_gripper.RobotiqGripper()   #???????\n",
    "# print(\"Connecting to grippers...\")\n",
    "\n",
    "\n",
    "# gripper_1.connect(ip1, 63352)                  # connect to the gripper\n",
    "                                           \n",
    "# robot_1 = urx.Robot(ip1, use_rt=True)            # connect to the UR robot\n",
    "\n",
    "\n",
    "# gripper_2.connect(ip2, 63352)                  # connect to the gripper\n",
    "                                           \n",
    "# robot_2 = urx.Robot(ip2, use_rt=True)            # connect to the UR robot\n",
    "\n",
    "\n",
    "\n",
    "# def move_top(robot_id, gripper_id , object_position):  \n",
    "#     return \"\"\n",
    "\n",
    "# def gripper_open(robot_id, gripper_id):\n",
    "#     gripper_id.move_and_wait_for_pos(0,100,100)\n",
    "\n",
    "\n",
    "\n",
    "############################# functions used in prompting  \n",
    "\n",
    "def move_to_object(robot_id, gripper_id, object_position): # to move to the position of an object\n",
    "    return \" move_to_object(robot_id, gripper_id, object_position) \" # for testing\n",
    "\n",
    "\n",
    "def grasp_object(robot_id, gripper_id, object_position):  # to grasp an object\n",
    "    return \" grasp_object(robot_id, gripper_id, object_position) \" # for testing\n",
    "\n",
    "def connect(robot_id, gripper_id, object_1_position, object_2_position): # connect a part to another\n",
    "    return \" connect(robot_id, gripper_id, object_1_position, object_2_position)\" # for testing\n",
    "\n",
    "def hold_object(robot_id, gripper_id, object_position): # To apply a forcce on the base to avoid it moving\n",
    "    return \" hold_object(robot_id, gripper_id, object_position) \" # for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "703afc2b-d2e0-4f43-8d7e-e85b41682451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langgraph\n",
    "# ! pip install langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0cf80c-f4a9-43ea-8ea7-5cb55811b071",
   "metadata": {},
   "source": [
    "## JSON file details extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d7b918-695b-4e8f-b28f-47707792a4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af767e53-d8dc-47ba-9f67-b281543160ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All output has been saved to output.txt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "class AssemblyEnvironment:\n",
    "    def __init__(self, json_file):\n",
    "        with open(json_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        self.base = data['assembly']['base']\n",
    "        self.base_num_pins=len(self.base[\"pins\"])\n",
    "        self.parts = data['assembly']['parts']\n",
    "        self.num_parts = len(self.parts)\n",
    "        self.base_position = data['assembly']['base']['position']\n",
    "\n",
    "        # Dynamically create pin attributes\n",
    "        for i in range(len(self.base[\"pins\"])):\n",
    "            pin_name = f\"base_pin_{i + 1}\"  # Create dynamic pin names\n",
    "            setattr(self, pin_name, self.base[\"pins\"][i])\n",
    "        \n",
    "        # Extract part details dynamically\n",
    "        for i, part in enumerate(self.parts):\n",
    "            part_id = part[\"id\"]\n",
    "            setattr(self, f\"{part_id}_position\", part[\"position\"])\n",
    "            setattr(self, f\"{part_id}_target_position\", part[\"target_position\"])\n",
    "            setattr(self, f\"{part_id}_mounting_hole\", part[\"mounting_hole\"])\n",
    "            setattr(self, f\"{part_id}_grip_pin\", part[\"grip_pin\"])\n",
    "\n",
    "        self.assembly_prompt  = lambda user_query: f\"\"\" \n",
    "You are an AI agent which task is to provide a detail plan for fully assembling an object of {self.num_parts + 1 } different components. \n",
    "The object has a base with { self.base_num_pins } pins where the  {self.num_parts} others parts which all contains amounting hole have to be mounted.\n",
    "The object have to be assembled by two robot (Robot1_base_holder ,Robot2_assembler) manipulator each equipped with a gripper (gripper1, gripper2)and \n",
    "your goal is to provide a deatailed plan on how the to robots have to collaborate togother to solve the assembly task by strictly using \n",
    "the following functions to control the motions of the two robots: move_to_object(robot_id, gripper_id, object_position), \n",
    "grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position), \n",
    "connect(robot_id, gripper_id, object_1_position, object_2_position).\n",
    "\n",
    "In order to answer use the following template:\n",
    "\n",
    "START OF PLAN\n",
    " step 1 - [CHOICE:  Robot1_base_holder,Robot2_assembler]  should move to the position of the base using the function [CHOICE: move_to_object(robot_id, gripper_id, object_position), \n",
    "   grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position)]\n",
    " step 2 - [CHOICE:  Robot1_base_holder,Robot2_assembler]  should hold the base using the function [CHOICE: move_to_object(robot_id, gripper_id, object_position), \n",
    "grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position), \n",
    "connect(robot_id, gripper_id, object_1_position, object_2_position)]\n",
    " step 3 - [CHOICE:  Robot1_base_holder,Robot2_assembler]  shoul move to the positon of [CHOICE: part_1, part_2, ....] with the function  [CHOICE: move_to_object(robot_id, gripper_id, object_position), \n",
    "grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position), connect(robot_id, gripper_id, object_1_position, object_2_position)]\n",
    " step 4 - [CHOICE:  Robot1_base_holder,Robot2_assembler]  should move grasp [CHOICE: part_1, part_2, ....] with the function  [CHOICE: move_to_object(robot_id, gripper_id, object_position), \n",
    "grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position), \n",
    "connect(robot_id, gripper_id, object_1_position, object_2_position)]\n",
    " step 5 - [CHOICE:  Robot1_base_holder,Robot2_assembler]  should connect  [CHOICE: part_1, part_2, ....] to the pin  [CHOICE: pin_1, pin_2, ....] on the base with the function\n",
    "[CHOICE: move_to_object(robot_id, gripper_id, object_position), grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position), \n",
    "connect(robot_id, gripper_id, object_1_position, object_2_position)]\n",
    " step 6 - .....\n",
    "END OF PLAN\n",
    "\n",
    "\n",
    "Rules:\n",
    "1. your answer should explicitly start with 'START OF PLAN' and end it with 'END OF PLAN' .\n",
    "2. When you see phrases like [CHOICE: choice1, choice2, ...], you should replace the entire phrase with only one of the choices listed.\n",
    "3. only Robot1_base_holder should hold the base for satability reasons when Robot2_assembler is doing the assembly task\n",
    "\n",
    "\n",
    "Example output:\n",
    "START OF PLAN\n",
    " 1 - Robot1_base_holder should move to the position of the base using the function move_to_object(robot1_base_holder, gripper1, base_position), \n",
    " 2  .....\n",
    "END OF PLAN\n",
    "\n",
    "\n",
    "Now here is the user given task : {user_query}\n",
    "\"\"\"    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Redirect stdout to a file\n",
    "    original_stdout = sys.stdout  # Save a reference to the original standard output\n",
    "\n",
    "    with open('output.txt', 'w') as f:\n",
    "        sys.stdout = f  # Change the standard output to the file we created.\n",
    "\n",
    "        # Create an instance of AssemblyEnvironment by providing the path to the JSON file\n",
    "        assembly_env = AssemblyEnvironment('assembly_details.JSON')\n",
    "\n",
    "        \n",
    "        print(\"On The Base:\")\n",
    "        \n",
    "        # Print the base and pins to verify\n",
    "        for pin in assembly_env.base[\"pins\"]:\n",
    "            pin_id = pin[\"id\"]\n",
    "            pin_position = pin[\"position\"]\n",
    "            print(f\"Pin {pin_id} Position on the base:\", pin_position)  # Print pin position\n",
    "\n",
    "\n",
    "        print(\"\\n\")\n",
    "        print(f\"The {assembly_env.num_parts} assembly parts:\")\n",
    "        \n",
    "        # Accessing dynamic part attributes with detailed descriptions\n",
    "        for part in assembly_env.parts:\n",
    "            part_id = part[\"id\"]\n",
    "            print(f\"Part {part_id}:\")\n",
    "            # print(f\"{part_id} Position:\", getattr(assembly_env, f\"{part_id}_position\"))  # Position of the part\n",
    "            print(f\"{part_id} Target Position:\", getattr(assembly_env, f\"{part_id}_target_position\"))  # Target position of the part\n",
    "            print(f\"{part_id} Mounting Hole:\", getattr(assembly_env, f\"{part_id}_mounting_hole\"))  # Mounting hole details of the part\n",
    "            print(f\"{part_id} Grip Pin:\", getattr(assembly_env, f\"{part_id}_grip_pin\"))  # Grip pin position of the part\n",
    "            print(\"-----------\")\n",
    "            \n",
    "        sys.stdout = original_stdout  # Reset the standard output to its original value\n",
    "\n",
    "print(\"All output has been saved to output.txt\")\n",
    "# print(assembly_env.assembly_prompt(\"hollllllllllllllllllllllllllla\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36277eeb-837f-4eec-a76f-6bfb4087f92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7590d903-a371-4279-b34f-c45cbc41b791",
   "metadata": {},
   "source": [
    "## RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "192a7dfd-23a6-4ab9-9626-70a01d13712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-community\n",
    "# !pip install sentence_transformers\n",
    "# !pip install --upgrade chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0457b567-1d6c-4e08-8027-704996cc271c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koffi/anaconda3/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'output.txt'}, page_content=\"part_2 Mounting Hole: {'id': 2, 'position': {'x': 0, 'y': 0, 'alpha': 0}}\")]\n"
     ]
    }
   ],
   "source": [
    "################################################################ RAG\n",
    "\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "### Reading the txt files from source directory\n",
    "\n",
    "loader = DirectoryLoader('./', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "### Creating Chunks using RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len\n",
    ")\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n",
    "doc_strings = [doc.page_content for doc in new_docs]\n",
    "\n",
    "###  BGE Embddings\n",
    "\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")\n",
    "\n",
    "### Creating Retriever using Vector DB\n",
    "\n",
    "db = Chroma.from_documents(new_docs, embeddings)\n",
    "# retriever = db.as_retriever(search_kwargs={\"k\": 4})\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################### testing RAG\n",
    "query = \"what is the Mounting Hole of part 2\"\n",
    "docs = retriever.invoke(query)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9570a578-a80e-4492-bb15-da0d735f4780",
   "metadata": {},
   "source": [
    "## Building agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa163e3-0e23-49cf-9eb5-cff62b2995c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "import operator\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import functools\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e986c4ec-d376-4e47-b10f-9c0ea11d9991",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Now you can access your environment variables using os.environ\n",
    "os.environ['OPENAI_API_KEY'] = ''\n",
    "# os.environ['TAVILY_API_KEY'] = os.environ.get(\"TAVILY_API_KEY\")\n",
    "\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49f224b8-87ca-433f-9ea0-8a62c4df2ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_plan(plan_text):\n",
    "    # Split the input text into lines\n",
    "    lines = plan_text.strip().split('\\n')\n",
    "    \n",
    "    # Initialize an empty list to hold the formatted output\n",
    "    formatted_lines = []\n",
    "    \n",
    "    # Flag to indicate if we are within the plan section\n",
    "    in_plan = False\n",
    "    \n",
    "    # Iterate over the lines\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line == \"START OF PLAN\":\n",
    "            in_plan = True\n",
    "            continue\n",
    "        elif line == \"END OF PLAN\":\n",
    "            break\n",
    "        \n",
    "        # If we are in the plan section, format the line\n",
    "        if in_plan and line:\n",
    "            formatted_lines.append(f'\"{line}\"')\n",
    "    \n",
    "    # Return the formatted lines joined by newline characters\n",
    "    return '\\n'.join(formatted_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc033ac1-2622-4b15-bd60-055f34215ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_plan_step1(state):\n",
    "    print('-> ...Plan Generation 1... ->')\n",
    "    messages = state['messages']\n",
    "    user_query = messages[-1]   ## Fetching the user question\n",
    "    complete_query = assembly_env.assembly_prompt( user_query) # to do\n",
    "    response = llm.invoke(complete_query)\n",
    "    state['messages'].append(response.content) # appending LLM call response to the AgentState\n",
    "    print('-> ...Plan Generation 1 Done... ->')\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def generate_plan_step2(state, filename = 'output.txt' ):\n",
    "    print('-> ...Plan Generation 2... ->')\n",
    "    \n",
    "    messages = state['messages']\n",
    "    plan = messages[-1] ## Fetching the user question\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        context = file.read() #to check later \n",
    "    \n",
    "    question = \"Now here is the plan to fill up: \\n \" + plan\n",
    "    # print('Question:',question)\n",
    "\n",
    "    template_format = lambda ctext, quest : f\"\"\"You will recieve a plan generated by an AI agent which contain a list of step that two robot manipulators \n",
    "have to follow in order to perform a user given task. The plan contain some functions and your goal is to replace the arguments \n",
    "of the function by their real values. All the reals variables values can be find in the following retrieved context:\\n\n",
    "    {ctext}\n",
    "\n",
    "    Question: {quest}\n",
    "    \"\"\"\n",
    "    template = template_format(context,question)\n",
    "    print('template:',template)\n",
    "    # prompt = ChatPromptTemplate.from_template(template)\n",
    "    # print(\"debug\")\n",
    "    # retrieval_chain = (\n",
    "    #     {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    #     | prompt\n",
    "    #     | llm\n",
    "    #     | StrOutputParser()\n",
    "    #     )\n",
    "    # result = retrieval_chain.invoke(question)\n",
    "\n",
    "    response = llm.invoke(template)\n",
    "    clean_response = transform_plan(response.content)\n",
    "    # clean_response = response\n",
    "    state[\"messages\"] = []\n",
    "    state['messages'].append(clean_response) # appending LLM call response to the AgentState\n",
    "    print('-> ...Plan Generation 2 Done... ->')\n",
    "    return state\n",
    "    \n",
    "    # return result\n",
    "    \n",
    "################################################################ Supervisor\n",
    "\n",
    "\n",
    "\n",
    "# from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "# from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "members = [\"Robot1_base_holder\", \"Robot2_assembler\"]\n",
    "system_prompt = (\n",
    "'''\n",
    "You are a supervisor you have to manage the task allocation between the following two robot workers: {members}. \n",
    "You will recieve a plan that contain several steps. Follow the rules below:\n",
    "\n",
    "Rules\n",
    "1- The steps are supposed to be performed one after another \n",
    "2- At each step choose Robot1_base_holder if the task is suppose to be performed by it  or Robot2_assembler in the opposite case. \n",
    "3- When all steps are done, respond with FINISH\n",
    "\n",
    "Example:\n",
    "'''\n",
    ")\n",
    "\n",
    "options = [\"FINISH\"] + members\n",
    "# Using openai function calling can make output parsing easier for us\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"next\": {\n",
    "                \"title\": \"Next\",\n",
    "                \"anyOf\": [\n",
    "                    {\"enum\": options},\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "supervisor_chain = (\n",
    "    prompt\n",
    "    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "    | JsonOutputFunctionsParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a64fb623-d096-4b02-8c99-5e0edf6a07f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "# from langchain_core.messages import BaseMessage, HumanMessage\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    # Each worker node will be given a name and some tools.\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ade846c2-ad1e-47f4-8337-609002a60f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc1aafaa-09e0-4da9-b868-ed39f81b386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from langchain_core.messages import ToolMessage\n",
    "# from langchain_core.tools import tool\n",
    "# from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "\n",
    "# from langchain_core.tools import BaseTool\n",
    "\n",
    "# from langchain_core.tools import BaseTool\n",
    "\n",
    "class MoveToObjectTool(BaseTool):\n",
    "    name = \"MoveToObjectTool\"\n",
    "    description = \"Moves the robot to a specified object's position.\"\n",
    "    \n",
    "    def _run(self, robot_id: str, gripper_id: str, object_position: str) -> str:\n",
    "        return move_to_object(robot_id, gripper_id, object_position)\n",
    "\n",
    "class GraspObjectTool(BaseTool):\n",
    "    name = \"GraspObjectTool\"\n",
    "    description = \"Grasps an object with the robot's gripper.\"\n",
    "    \n",
    "    def _run(self, robot_id: str, gripper_id: str, object_position: str) -> str:\n",
    "        return grasp_object(robot_id, gripper_id, object_position)\n",
    "\n",
    "class HoldObjectTool(BaseTool):\n",
    "    name = \"HoldObjectTool\"\n",
    "    description = \"Holds an object with the robot's gripper.\"\n",
    "    \n",
    "    def _run(self, robot_id: str, gripper_id: str, object_position: str) -> str:\n",
    "        return hold_object(robot_id, gripper_id, object_position)\n",
    "\n",
    "class ConnectTool(BaseTool):\n",
    "    name = \"ConnectTool\"\n",
    "    description = \"Connects two objects using the robot's gripper.\"\n",
    "    \n",
    "    def _run(self, robot_id: str, gripper_id: str, object_1_position: str, object_2_position: str) -> str:\n",
    "        return connect(robot_id, gripper_id, object_1_position, object_2_position)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccb6ec7d-133d-45f4-ac66-a748eb7e333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "# from langchain_core.messages import BaseMessage, HumanMessage\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_core.runnables import RunnablePassthrough\n",
    "# from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    # Each worker node will be given a name and some tools.\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a29fed3-060b-441b-abd4-5e81caba3bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import operator\n",
    "# from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "# import functools\n",
    "\n",
    "# from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "robot1_agent = create_agent(\n",
    "    llm,\n",
    "     [\n",
    "        MoveToObjectTool(),  \n",
    "        GraspObjectTool(),\n",
    "        HoldObjectTool(),\n",
    "        ConnectTool(),\n",
    "    ],\n",
    "    'Use these tools when the task is supposed to be done by Robot1_base_holder'\n",
    ")\n",
    "\n",
    "robot1_node = functools.partial(agent_node, agent=robot1_agent, name=\"Robot1_base_holder\")\n",
    "\n",
    "\n",
    "robot2_agent = create_agent(\n",
    "    llm,\n",
    "     [\n",
    "        MoveToObjectTool(),  \n",
    "        GraspObjectTool(),\n",
    "        HoldObjectTool(),\n",
    "        ConnectTool(),\n",
    "    ],\n",
    "    'Use this tools when task is supposed to be done by Robot2_assembler'\n",
    ")\n",
    "robot2_node = functools.partial(agent_node, agent=robot2_agent, name=\"Robot2_assembler\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e7ed994-2584-49a9-8b54-4479634ef652",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "\n",
    "workflow.add_node(\"generate_plan1\", generate_plan_step1)\n",
    "workflow.add_node(\"generate_plan2\", generate_plan_step2)\n",
    "workflow.add_edge('generate_plan1', 'generate_plan2')\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)\n",
    "workflow.add_edge('generate_plan2','supervisor')\n",
    "workflow.add_node(\"Robot1_base_holder\", robot1_node)\n",
    "workflow.add_node(\"Robot2_assembler\", robot2_node)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for member in members:\n",
    "    # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "# Finally, add entrypoint\n",
    "workflow.set_entry_point(\"generate_plan1\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02a45303-17c0-4983-83b1-666373bac7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> ...Plan Generation 1... ->\n",
      "-> ...Plan Generation 1 Done... ->\n",
      "{'generate_plan1': {'messages': [HumanMessage(content='assemble a gripper of one base and two parts for me'), 'START OF PLAN\\nstep 1 - Robot1_base_holder should move to the position of the base using the function move_to_object(robot1_base_holder, gripper1, base_position),\\nstep 2 - Robot1_base_holder should grasp the base using the function grasp_object(robot1_base_holder, gripper1, base_position),\\nstep 3 - Robot2_assembler should move to the position of part_1 with the function move_to_object(robot2_assembler, gripper2, part_1_position),\\nstep 4 - Robot2_assembler should grasp part_1 with the function grasp_object(robot2_assembler, gripper2, part_1_position),\\nstep 5 - Robot2_assembler should connect part_1 to pin_1 on the base with the function connect(robot2_assembler, gripper2, part_1_position, pin_1_position),\\nstep 6 - Robot2_assembler should move to the position of part_2 with the function move_to_object(robot2_assembler, gripper2, part_2_position),\\nstep 7 - Robot2_assembler should grasp part_2 with the function grasp_object(robot2_assembler, gripper2, part_2_position),\\nstep 8 - Robot2_assembler should connect part_2 to pin_2 on the base with the function connect(robot2_assembler, gripper2, part_2_position, pin_2_position),\\nEND OF PLAN']}}\n",
      "----\n",
      "-> ...Plan Generation 2... ->\n",
      "template: You will recieve a plan generated by an AI agent which contain a list of step that two robot manipulators \n",
      "have to follow in order to perform a user given task. The plan contain some functions and your goal is to replace the arguments \n",
      "of the function by their real values. All the reals variables values can be find in the following retrieved context:\n",
      "\n",
      "    On The Base:\n",
      "Pin 1 Position on the base: {'x': -25, 'y': 0, 'alpha': 0}\n",
      "Pin 2 Position on the base: {'x': 25, 'y': 0, 'alpha': 0}\n",
      "\n",
      "\n",
      "The 2 assembly parts:\n",
      "Part part_1:\n",
      "part_1 Target Position: {'x': -25, 'y': 0, 'alpha': 0}\n",
      "part_1 Mounting Hole: {'id': 1, 'position': {'x': 0, 'y': 0, 'alpha': 0}}\n",
      "part_1 Grip Pin: {'position': {'x': -40, 'y': 15, 'alpha': 0}}\n",
      "-----------\n",
      "Part part_2:\n",
      "part_2 Target Position: {'x': 25, 'y': 0, 'alpha': 0}\n",
      "part_2 Mounting Hole: {'id': 2, 'position': {'x': 0, 'y': 0, 'alpha': 0}}\n",
      "part_2 Grip Pin: {'position': {'x': 40, 'y': 15, 'alpha': 0}}\n",
      "-----------\n",
      "\n",
      "\n",
      "    Question: Now here is the plan to fill up: \n",
      " START OF PLAN\n",
      "step 1 - Robot1_base_holder should move to the position of the base using the function move_to_object(robot1_base_holder, gripper1, base_position),\n",
      "step 2 - Robot1_base_holder should grasp the base using the function grasp_object(robot1_base_holder, gripper1, base_position),\n",
      "step 3 - Robot2_assembler should move to the position of part_1 with the function move_to_object(robot2_assembler, gripper2, part_1_position),\n",
      "step 4 - Robot2_assembler should grasp part_1 with the function grasp_object(robot2_assembler, gripper2, part_1_position),\n",
      "step 5 - Robot2_assembler should connect part_1 to pin_1 on the base with the function connect(robot2_assembler, gripper2, part_1_position, pin_1_position),\n",
      "step 6 - Robot2_assembler should move to the position of part_2 with the function move_to_object(robot2_assembler, gripper2, part_2_position),\n",
      "step 7 - Robot2_assembler should grasp part_2 with the function grasp_object(robot2_assembler, gripper2, part_2_position),\n",
      "step 8 - Robot2_assembler should connect part_2 to pin_2 on the base with the function connect(robot2_assembler, gripper2, part_2_position, pin_2_position),\n",
      "END OF PLAN\n",
      "    \n",
      "-> ...Plan Generation 2 Done... ->\n",
      "{'generate_plan2': {'messages': ['\"1. **step 1** - Robot1_base_holder should move to the position of the base using the function move_to_object(robot1_base_holder, gripper1, {\\'x\\': 0, \\'y\\': 0, \\'alpha\\': 0}),\"\\n\"2. **step 2** - Robot1_base_holder should grasp the base using the function grasp_object(robot1_base_holder, gripper1, {\\'x\\': 0, \\'y\\': 0, \\'alpha\\': 0}),\"\\n\"3. **step 3** - Robot2_assembler should move to the position of part_1 with the function move_to_object(robot2_assembler, gripper2, {\\'x\\': -25, \\'y\\': 0, \\'alpha\\': 0}),\"\\n\"4. **step 4** - Robot2_assembler should grasp part_1 with the function grasp_object(robot2_assembler, gripper2, {\\'x\\': -25, \\'y\\': 0, \\'alpha\\': 0}),\"\\n\"5. **step 5** - Robot2_assembler should connect part_1 to pin_1 on the base with the function connect(robot2_assembler, gripper2, {\\'x\\': -25, \\'y\\': 0, \\'alpha\\': 0}, {\\'x\\': -25, \\'y\\': 0, \\'alpha\\': 0}),\"\\n\"6. **step 6** - Robot2_assembler should move to the position of part_2 with the function move_to_object(robot2_assembler, gripper2, {\\'x\\': 25, \\'y\\': 0, \\'alpha\\': 0}),\"\\n\"7. **step 7** - Robot2_assembler should grasp part_2 with the function grasp_object(robot2_assembler, gripper2, {\\'x\\': 25, \\'y\\': 0, \\'alpha\\': 0}),\"\\n\"8. **step 8** - Robot2_assembler should connect part_2 to pin_2 on the base with the function connect(robot2_assembler, gripper2, {\\'x\\': 25, \\'y\\': 0, \\'alpha\\': 0}, {\\'x\\': 25, \\'y\\': 0, \\'alpha\\': 0}),\"']}}\n",
      "----\n",
      "{'supervisor': {'next': 'Robot1_base_holder'}}\n",
      "----\n",
      "{'Robot1_base_holder': {'messages': [HumanMessage(content='The Robot1_base_holder has successfully moved to the position of the base and grasped it. Steps 1 and 2 of the plan have been completed. Please proceed with the next steps involving Robot2_assembler to continue the assembly of the gripper.', name='Robot1_base_holder')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'Robot2_assembler'}}\n",
      "----\n",
      "{'Robot2_assembler': {'messages': [HumanMessage(content=\"The assembly of the gripper has been successfully completed. Here's a summary of the actions performed by Robot2_assembler:\\n\\n- Moved to and grasped part_1.\\n- Connected part_1 to pin_1 on the base.\\n- Moved to and grasped part_2.\\n- Connected part_2 to pin_2 on the base.\\n\\nThe gripper is now fully assembled.\", name='Robot2_assembler')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"assemble a gripper of one base and two parts for me\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad50720-1789-4995-a897-c852385dca3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a3e72-6c70-4fc2-b1d0-fb0428de6159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5e5469-42a5-402b-8e55-f24fb88ef0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9363f558-872c-46d3-8009-7b913544771c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795906f-1410-4dc2-b9b7-2b06e9079418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef60e3a-0cdd-4db2-ac69-bb3c9166fad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
