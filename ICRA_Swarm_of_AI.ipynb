{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e890c00-6a42-48c6-a1ba-5e3d0450037f",
   "metadata": {},
   "source": [
    "# Robot functions (to be completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "340ff3f5-d340-4d1f-bbc5-75dc5b21d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install math3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02e9bb0b-3bbc-4c02-b0cc-3ca56aba48d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import urx\n",
    "# import robotiq_gripper\n",
    "\n",
    "# ip1 = \"192.168.2.207\"   #ip of the UR robot to connect\n",
    "\n",
    "# ip2 = \"\"   #???????\n",
    "\n",
    "# gripper_1 = robotiq_gripper.RobotiqGripper()  # initialize the gripper\n",
    "# gripper_2 = robotiq_gripper.RobotiqGripper()   #???????\n",
    "# print(\"Connecting to grippers...\")\n",
    "\n",
    "\n",
    "# gripper_1.connect(ip1, 63352)                  # connect to the gripper\n",
    "                                           \n",
    "# robot_1 = urx.Robot(ip1, use_rt=True)            # connect to the UR robot\n",
    "\n",
    "\n",
    "# gripper_2.connect(ip2, 63352)                  # connect to the gripper\n",
    "                                           \n",
    "# robot_2 = urx.Robot(ip2, use_rt=True)            # connect to the UR robot\n",
    "\n",
    "\n",
    "\n",
    "# def move_top(robot_id, gripper_id , object_position):  \n",
    "#     return \"\"\n",
    "\n",
    "# def gripper_open(robot_id, gripper_id):\n",
    "#     gripper_id.move_and_wait_for_pos(0,100,100)\n",
    "\n",
    "\n",
    "\n",
    "############################# functions used in prompting \n",
    "\n",
    "def move_to_object(robot_id, gripper_id, object_position): # to move to the position of an object\n",
    "    return \" move_to_object(robot_id, gripper_id, object_position) \" # for testing\n",
    "\n",
    "\n",
    "def grasp_object(robot_id, gripper_id, object_position):  # to grasp an object\n",
    "    return \" grasp_object(robot_id, gripper_id, object_position) \" # for testing\n",
    "\n",
    "def connect(robot_id, gripper_id, object_1_position, object_2_position): # connect a part to another\n",
    "    return \" connect(robot_id, gripper_id, object_1_position, object_2_position)\" # for testing\n",
    "\n",
    "def hold_object(robot_id, gripper_id, object_position): # To apply a forcce on the base to avoid it moving\n",
    "    return \" hold_object(robot_id, gripper_id, object_position) \" # for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "703afc2b-d2e0-4f43-8d7e-e85b41682451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langgraph\n",
    "# ! pip install langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0cf80c-f4a9-43ea-8ea7-5cb55811b071",
   "metadata": {},
   "source": [
    "## JSON file details extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d7b918-695b-4e8f-b28f-47707792a4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af767e53-d8dc-47ba-9f67-b281543160ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All output has been saved to output.txt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "class AssemblyEnvironment:\n",
    "    def __init__(self, json_file):\n",
    "        with open(json_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        self.base = data['assembly']['base']\n",
    "        self.base_num_pins=len(self.base[\"pins\"])\n",
    "        self.parts = data['assembly']['parts']\n",
    "        self.num_parts = len(self.parts)\n",
    "        self.base_position = data['assembly']['base']['position']\n",
    "\n",
    "        # Dynamically create pin attributes\n",
    "        for i in range(len(self.base[\"pins\"])):\n",
    "            pin_name = f\"base_pin_{i + 1}\"  # Create dynamic pin names\n",
    "            setattr(self, pin_name, self.base[\"pins\"][i])\n",
    "        \n",
    "        # Extract part details dynamically\n",
    "        for i, part in enumerate(self.parts):\n",
    "            part_id = part[\"id\"]\n",
    "            setattr(self, f\"{part_id}_position\", part[\"position\"])\n",
    "            setattr(self, f\"{part_id}_target_position\", part[\"target_position\"])\n",
    "            setattr(self, f\"{part_id}_mounting_hole\", part[\"mounting_hole\"])\n",
    "            setattr(self, f\"{part_id}_grip_pin\", part[\"grip_pin\"])\n",
    "\n",
    "        self.assembly_prompt  = lambda user_query: f\"\"\" \n",
    "You are an AI agent which task is to provide a detail plan for fully assembling an object of {self.num_parts + 1 } different components. \n",
    "The object has a base with { self.base_num_pins } pins where the  {self.num_parts} others parts which all contains amounting hole have to be mounted.\n",
    "The object have to be assembled by two robot (Robot1_base_holder ,Robot2_assembler) manipulator each equipped with a gripper (gripper1, gripper2)and \n",
    "your goal is to provide a deatailed plan on how the to robots have to collaborate togother to solve the assembly task by strictly using \n",
    "the following functions to control the motions of the two robots: move_to_object(robot_id, gripper_id, object_position), \n",
    "grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position), \n",
    "connect(robot_id, gripper_id, object_1_position, object_2_position).\n",
    "\n",
    "In order to answer use the following template:\n",
    "\n",
    "START OF PLAN\n",
    " 1 - [CHOICE:  Robot1_base_holder,Robot2_assembler]  should move to the position of the base using the function [CHOICE: move_to_object(robot_id, gripper_id, object_position), \n",
    "   grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position)]\n",
    " 2 - [CHOICE:  Robot1_base_holder,Robot2_assembler]  should hold the base using the function [CHOICE: move_to_object(robot_id, gripper_id, object_position), \n",
    "grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position), \n",
    "connect(robot_id, gripper_id, object_1_position, object_2_position)]\n",
    " 3 - [CHOICE:  Robot1_base_holder,Robot2_assembler]  shoul move to the positon of [CHOICE: part_1, part_2, ....] with the function  [CHOICE: move_to_object(robot_id, gripper_id, object_position), \n",
    "grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position), connect(robot_id, gripper_id, object_1_position, object_2_position)]\n",
    " 4 - [CHOICE:  Robot1_base_holder,Robot2_assembler]  should move grasp [CHOICE: part_1, part_2, ....] with the function  [CHOICE: move_to_object(robot_id, gripper_id, object_position), \n",
    "grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position), \n",
    "connect(robot_id, gripper_id, object_1_position, object_2_position)]\n",
    " 5 - [CHOICE:  Robot1_base_holder,Robot2_assembler]  should connect  [CHOICE: part_1, part_2, ....] to the pin  [CHOICE: pin_1, pin_2, ....] on the base with the function\n",
    "[CHOICE: move_to_object(robot_id, gripper_id, object_position), grasp_object(robot_id, gripper_id, object_position),  hold_object(robot_id, gripper_id, object_position), \n",
    "connect(robot_id, gripper_id, object_1_position, object_2_position)]\n",
    " 6 - .....\n",
    "END OF PLAN\n",
    "\n",
    "\n",
    "Rules:\n",
    "1. your answer should explicitly start with 'START OF PLAN' and end it with 'END OF PLAN' .\n",
    "2. When you see phrases like [CHOICE: choice1, choice2, ...], you should replace the entire phrase with only one of the choices listed.\n",
    "4. Do not create or invent any other function; only use the provided predifined used functions  \n",
    "\n",
    "Now here is the user given task : {user_query}\"\"\"    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Redirect stdout to a file\n",
    "    original_stdout = sys.stdout  # Save a reference to the original standard output\n",
    "\n",
    "    with open('output.txt', 'w') as f:\n",
    "        sys.stdout = f  # Change the standard output to the file we created.\n",
    "\n",
    "        # Create an instance of AssemblyEnvironment by providing the path to the JSON file\n",
    "        assembly_env = AssemblyEnvironment('assembly_details.JSON')\n",
    "\n",
    "        \n",
    "        print(\"On The Base:\")\n",
    "        \n",
    "        # Print the base and pins to verify\n",
    "        for pin in assembly_env.base[\"pins\"]:\n",
    "            pin_id = pin[\"id\"]\n",
    "            pin_position = pin[\"position\"]\n",
    "            print(f\"Pin {pin_id} Position on the base:\", pin_position)  # Print pin position\n",
    "\n",
    "\n",
    "        print(\"\\n\")\n",
    "        print(f\"The {assembly_env.num_parts} assembly parts:\")\n",
    "        \n",
    "        # Accessing dynamic part attributes with detailed descriptions\n",
    "        for part in assembly_env.parts:\n",
    "            part_id = part[\"id\"]\n",
    "            print(f\"Part {part_id}:\")\n",
    "            # print(f\"{part_id} Position:\", getattr(assembly_env, f\"{part_id}_position\"))  # Position of the part\n",
    "            print(f\"{part_id} Target Position:\", getattr(assembly_env, f\"{part_id}_target_position\"))  # Target position of the part\n",
    "            print(f\"{part_id} Mounting Hole:\", getattr(assembly_env, f\"{part_id}_mounting_hole\"))  # Mounting hole details of the part\n",
    "            print(f\"{part_id} Grip Pin:\", getattr(assembly_env, f\"{part_id}_grip_pin\"))  # Grip pin position of the part\n",
    "            print(\"-----------\")\n",
    "            \n",
    "        sys.stdout = original_stdout  # Reset the standard output to its original value\n",
    "\n",
    "print(\"All output has been saved to output.txt\")\n",
    "# print(assembly_env.assembly_prompt(\"hollllllllllllllllllllllllllla\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36277eeb-837f-4eec-a76f-6bfb4087f92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7590d903-a371-4279-b34f-c45cbc41b791",
   "metadata": {},
   "source": [
    "## RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "192a7dfd-23a6-4ab9-9626-70a01d13712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-community\n",
    "# !pip install sentence_transformers\n",
    "# !pip install --upgrade chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0457b567-1d6c-4e08-8027-704996cc271c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koffi/anaconda3/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'output.txt'}, page_content=\"part_2 Mounting Hole: {'id': 2, 'position': {'x': 0, 'y': 0, 'alpha': 0}}\")]\n"
     ]
    }
   ],
   "source": [
    "################################################################ RAG\n",
    "\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "### Reading the txt files from source directory\n",
    "\n",
    "loader = DirectoryLoader('./', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "### Creating Chunks using RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len\n",
    ")\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n",
    "doc_strings = [doc.page_content for doc in new_docs]\n",
    "\n",
    "###  BGE Embddings\n",
    "\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")\n",
    "\n",
    "### Creating Retriever using Vector DB\n",
    "\n",
    "db = Chroma.from_documents(new_docs, embeddings)\n",
    "# retriever = db.as_retriever(search_kwargs={\"k\": 4})\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################### testing RAG\n",
    "query = \"what is the Mounting Hole of part 2\"\n",
    "docs = retriever.invoke(query)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9570a578-a80e-4492-bb15-da0d735f4780",
   "metadata": {},
   "source": [
    "## Building agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa163e3-0e23-49cf-9eb5-cff62b2995c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e986c4ec-d376-4e47-b10f-9c0ea11d9991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Now you can access your environment variables using os.environ\n",
    "os.environ['OPENAI_API_KEY'] = ''\n",
    "# os.environ['TAVILY_API_KEY'] = os.environ.get(\"TAVILY_API_KEY\")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc033ac1-2622-4b15-bd60-055f34215ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def generate_plan(state):\n",
    "#     messages = state['messages']\n",
    "#     question = messages[0] ## Fetching the user question\n",
    "\n",
    "#     template = \"\"\"Answer the question based only on the following context:\n",
    "#     {context}\n",
    "\n",
    "#     Question: {question}\n",
    "#     \"\"\"\n",
    "#     prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "#     retrieval_chain = (\n",
    "#         {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "#         | prompt\n",
    "#         | llm\n",
    "#         | StrOutputParser()\n",
    "#         )\n",
    "#     result = retrieval_chain.invoke(question)\n",
    "#     return result\n",
    "\n",
    "\n",
    "\n",
    "def generate_plan_step1(user_query):\n",
    "    print('-> ...Plan Generation... ->')\n",
    "    complete_query = assembly_env.assembly_prompt( user_query) # to do\n",
    "    response = llm.invoke(complete_query)\n",
    "    plan = response.content\n",
    "    return  plan\n",
    "\n",
    "\n",
    "# def generate_plan_step2(plan):\n",
    "#     print('-> ...Calling RAG... ->')\n",
    "#     question = \"Use the position x,y and alpha provided in the context to fill the arguments of the functions in the following plan: \\n \" + plan\n",
    "#     print('Question:',question)\n",
    "\n",
    "#     template = \"\"\"Answer the question based only and strictly on the following context:\n",
    "#     {context}\n",
    "\n",
    "#     Question: {question}\n",
    "#     \"\"\"\n",
    "#     prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "#     retrieval_chain = (\n",
    "#         {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "#         | prompt\n",
    "#         | llm\n",
    "#         | StrOutputParser()\n",
    "#         )\n",
    "#     result = retrieval_chain.invoke(question)\n",
    "#     return result\n",
    "\n",
    "\n",
    "def generate_plan_step2(plan, filename = 'output.txt' ):\n",
    "    print('-> ...Calling RAG+-... ->')\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        context = file.read() #to check later \n",
    "    \n",
    "    question = \"Now here is the plan to fill up: \\n \" + plan\n",
    "    print('Question:',question)\n",
    "\n",
    "    template = \"\"\"You will recieve a plan generated by an AI agent which contain a list of step that two robot manipulators \n",
    "have to follow in order to perform a user given task. The plan contain some functions and your goal is to replace the arguments \n",
    "of the function by their real values. All the reals variables values can be find in the following retrieved context:\\n\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    print('template:',template)\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    retrieval_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "        )\n",
    "    result = retrieval_chain.invoke(question)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "################################################################ Supervisor\n",
    "\n",
    "\n",
    "\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "members = [\"Robot1_base_holder\", \"Robot2_assembler\"]\n",
    "system_prompt = (\n",
    "'''\n",
    "You are a supervisor tasked with managing a collaboration between the following two robot workers: {members}. \n",
    "Given the following user request, respond with the worker to act next. Use Robot1_base_holder \n",
    "is assigned to it and Robot2_assembler when the task i assigned to it . Each worker will perform his task and \n",
    "respond with their results and status. \n",
    "When finished, respond with FINISH\n",
    "'''\n",
    ")\n",
    "\n",
    "options = [\"FINISH\"] + members\n",
    "# Using openai function calling can make output parsing easier for us\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"next\": {\n",
    "                \"title\": \"Next\",\n",
    "                \"anyOf\": [\n",
    "                    {\"enum\": options},\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "supervisor_chain = (\n",
    "    prompt\n",
    "    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "    | JsonOutputFunctionsParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320f57d8-6e83-4582-8b28-5fb8607a6be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74451546-376e-4472-9d63-8c5feb901cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9ddc7b-f3e0-463a-9ea4-9e427b67e241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a64fb623-d096-4b02-8c99-5e0edf6a07f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    # Each worker node will be given a name and some tools.\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ade846c2-ad1e-47f4-8337-609002a60f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc1aafaa-09e0-4da9-b868-ed39f81b386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "\n",
    "# @tool\n",
    "\n",
    "\n",
    "# model_with_tools = model.bind(tools=[convert_to_openai_tool(multiply)])\n",
    "\n",
    "\n",
    "\n",
    "# @tool\n",
    "# def move_to_object_tool(robot_id, gripper_id, object_position):\n",
    "#     return move_to_object(robot_id, gripper_id, object_position)\n",
    "\n",
    "# @tool\n",
    "# def grasp_object_tool(robot_id, gripper_id, object_position):\n",
    "#     return grasp_object(robot_id, gripper_id, object_position)\n",
    "\n",
    "\n",
    "\n",
    "# @tool\n",
    "# def hold_object_tool(robot_id, gripper_id, object_position):\n",
    "#     return hold_object(robot_id, gripper_id, object_position)\n",
    "\n",
    "\n",
    "# @tool\n",
    "# def connect_tool(robot_id, gripper_id, object_1_position, object_2_position):\n",
    "#     return connect(robot_id, gripper_id, object_1_position, object_2_position)\n",
    "\n",
    "\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "class MoveToObjectTool(BaseTool):\n",
    "    def _run(self, robot_id, gripper_id, object_position):\n",
    "        # Implement the logic for moving the robot\n",
    "        return move_to_object(robot_id, gripper_id, object_position)\n",
    "\n",
    "class GraspObjectTool(BaseTool):\n",
    "    def _run(self, robot_id, gripper_id, object_position):\n",
    "        # Implement the logic for moving the robot\n",
    "        return grasp_object(robot_id, gripper_id, object_position)\n",
    "\n",
    "\n",
    "class HoldObjectTool(BaseTool):\n",
    "    def _run(self, robot_id, gripper_id, object_position):\n",
    "        # Implement the logic for moving the robot\n",
    "        return hold_object(robot_id, gripper_id, object_position)\n",
    "\n",
    "\n",
    "class ConnectTool(BaseTool):\n",
    "    def _run(self, robot_id, gripper_id, object_1_position, object_2_position):\n",
    "        # Implement the logic for moving the robot\n",
    "        return connect(robot_id, gripper_id, object_1_position, object_2_position)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# @tool\n",
    "# def move_to_object_tool(robot_id, gripper_id, object_position):\n",
    "#     \"\"\"Move the robot to the object position.\"\"\"\n",
    "#     return move_to_object(robot_id, gripper_id, object_position)\n",
    "\n",
    "# @tool\n",
    "# def grasp_object_tool(robot_id, gripper_id, object_position):\n",
    "#     \"\"\"Grasp the object at the specified position.\"\"\"\n",
    "#     return grasp_object(robot_id, gripper_id, object_position)\n",
    "\n",
    "# @tool\n",
    "# def hold_object_tool(robot_id, gripper_id, object_position):\n",
    "#     \"\"\"Hold the object at the specified position.\"\"\"\n",
    "#     return hold_object(robot_id, gripper_id, object_position)\n",
    "\n",
    "# @tool\n",
    "# def connect_tool(robot_id, gripper_id, object_1_position, object_2_position):\n",
    "#     \"\"\"Connect two objects at the specified positions.\"\"\"\n",
    "#     return connect(robot_id, gripper_id, object_1_position, object_2_position)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccb6ec7d-133d-45f4-ac66-a748eb7e333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    # Each worker node will be given a name and some tools.\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a29fed3-060b-441b-abd4-5e81caba3bdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Value not declarable with JSON Schema, field: name='_callbacks_List[langchain_core.callbacks.base.BaseCallbackHandler]' type=BaseCallbackHandler required=True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 75\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mnext\u001b[39m: \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# research_agent = create_agent(llm, [tavily_tool], \"You are a web researcher.\")\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#                                  [convert_to_openai_tool(move_to_object_tool),convert_to_openai_tool(grasp_object_tool),convert_to_openai_tool(hold_object_tool),convert_to_openai_tool(connect_tool)],\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#                                 'Use this tools when task is supposed to be done by Robot1_base_holder')\u001b[39;00m\n\u001b[1;32m     72\u001b[0m robot1_agent \u001b[38;5;241m=\u001b[39m create_agent(\n\u001b[1;32m     73\u001b[0m     llm,\n\u001b[1;32m     74\u001b[0m     [\n\u001b[0;32m---> 75\u001b[0m         convert_to_openai_tool(MoveToObjectTool),  \u001b[38;5;66;03m# Ensure proper instantiation\u001b[39;00m\n\u001b[1;32m     76\u001b[0m         convert_to_openai_tool(GraspObjectTool()),\n\u001b[1;32m     77\u001b[0m         convert_to_openai_tool(HoldObjectTool()),\n\u001b[1;32m     78\u001b[0m         convert_to_openai_tool(ConnectTool()),\n\u001b[1;32m     79\u001b[0m     ],\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse these tools when the task is supposed to be done by Robot1_base_holder\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     83\u001b[0m robot1_node \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(agent_node, agent\u001b[38;5;241m=\u001b[39mrobot1_agent, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobot1_base_holder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# robot2_agent = create_agent(llm,\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m#                                   [convert_to_openai_tool(move_to_object_tool),convert_to_openai_tool(grasp_object_tool),convert_to_openai_tool(hold_object_tool),convert_to_openai_tool(connect_tool)],\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m#                                  'Use this tools when task is supposed to be done by Robot2_assembler')\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:432\u001b[0m, in \u001b[0;36mconvert_to_openai_tool\u001b[0;34m(tool, strict)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m tool\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tool:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tool\n\u001b[0;32m--> 432\u001b[0m oai_function \u001b[38;5;241m=\u001b[39m convert_to_openai_function(tool, strict\u001b[38;5;241m=\u001b[39mstrict)\n\u001b[1;32m    433\u001b[0m oai_tool: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m: oai_function}\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m oai_tool\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:373\u001b[0m, in \u001b[0;36mconvert_to_openai_function\u001b[0;34m(function, strict)\u001b[0m\n\u001b[1;32m    367\u001b[0m     oai_function \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: function\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    369\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: function\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m: function,\n\u001b[1;32m    371\u001b[0m     }\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(function, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_basemodel_subclass(function):\n\u001b[0;32m--> 373\u001b[0m     oai_function \u001b[38;5;241m=\u001b[39m cast(Dict, convert_pydantic_to_openai_function(function))\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_typeddict(function):\n\u001b[1;32m    375\u001b[0m     oai_function \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m    376\u001b[0m         Dict, _convert_typed_dict_to_openai_function(cast(Type, function))\n\u001b[1;32m    377\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:180\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     emit_warning()\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:110\u001b[0m, in \u001b[0;36mconvert_pydantic_to_openai_function\u001b[0;34m(model, name, description, rm_titles)\u001b[0m\n\u001b[1;32m    108\u001b[0m     schema \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel_json_schema()  \u001b[38;5;66;03m# Pydantic 2\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     schema \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mschema()  \u001b[38;5;66;03m# Pydantic 1\u001b[39;00m\n\u001b[1;32m    111\u001b[0m schema \u001b[38;5;241m=\u001b[39m dereference_refs(schema)\n\u001b[1;32m    112\u001b[0m schema\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefinitions\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pydantic/v1/main.py:664\u001b[0m, in \u001b[0;36mBaseModel.schema\u001b[0;34m(cls, by_alias, ref_template)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cached\n\u001b[0;32m--> 664\u001b[0m s \u001b[38;5;241m=\u001b[39m model_schema(\u001b[38;5;28mcls\u001b[39m, by_alias\u001b[38;5;241m=\u001b[39mby_alias, ref_template\u001b[38;5;241m=\u001b[39mref_template)\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__schema_cache__[(by_alias, ref_template)] \u001b[38;5;241m=\u001b[39m s\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pydantic/v1/schema.py:188\u001b[0m, in \u001b[0;36mmodel_schema\u001b[0;34m(model, by_alias, ref_prefix, ref_template)\u001b[0m\n\u001b[1;32m    186\u001b[0m model_name_map \u001b[38;5;241m=\u001b[39m get_model_name_map(flat_models)\n\u001b[1;32m    187\u001b[0m model_name \u001b[38;5;241m=\u001b[39m model_name_map[model]\n\u001b[0;32m--> 188\u001b[0m m_schema, m_definitions, nested_models \u001b[38;5;241m=\u001b[39m model_process_schema(\n\u001b[1;32m    189\u001b[0m     model, by_alias\u001b[38;5;241m=\u001b[39mby_alias, model_name_map\u001b[38;5;241m=\u001b[39mmodel_name_map, ref_prefix\u001b[38;5;241m=\u001b[39mref_prefix, ref_template\u001b[38;5;241m=\u001b[39mref_template\n\u001b[1;32m    190\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m nested_models:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# model_name is in Nested models, it has circular references\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     m_definitions[model_name] \u001b[38;5;241m=\u001b[39m m_schema\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pydantic/v1/schema.py:581\u001b[0m, in \u001b[0;36mmodel_process_schema\u001b[0;34m(model, by_alias, model_name_map, ref_prefix, ref_template, known_models, field)\u001b[0m\n\u001b[1;32m    579\u001b[0m     s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m doc\n\u001b[1;32m    580\u001b[0m known_models\u001b[38;5;241m.\u001b[39madd(model)\n\u001b[0;32m--> 581\u001b[0m m_schema, m_definitions, nested_models \u001b[38;5;241m=\u001b[39m model_type_schema(\n\u001b[1;32m    582\u001b[0m     model,\n\u001b[1;32m    583\u001b[0m     by_alias\u001b[38;5;241m=\u001b[39mby_alias,\n\u001b[1;32m    584\u001b[0m     model_name_map\u001b[38;5;241m=\u001b[39mmodel_name_map,\n\u001b[1;32m    585\u001b[0m     ref_prefix\u001b[38;5;241m=\u001b[39mref_prefix,\n\u001b[1;32m    586\u001b[0m     ref_template\u001b[38;5;241m=\u001b[39mref_template,\n\u001b[1;32m    587\u001b[0m     known_models\u001b[38;5;241m=\u001b[39mknown_models,\n\u001b[1;32m    588\u001b[0m )\n\u001b[1;32m    589\u001b[0m s\u001b[38;5;241m.\u001b[39mupdate(m_schema)\n\u001b[1;32m    590\u001b[0m schema_extra \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m__config__\u001b[38;5;241m.\u001b[39mschema_extra\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pydantic/v1/schema.py:622\u001b[0m, in \u001b[0;36mmodel_type_schema\u001b[0;34m(model, by_alias, model_name_map, ref_template, ref_prefix, known_models)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, f \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39m__fields__\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         f_schema, f_definitions, f_nested_models \u001b[38;5;241m=\u001b[39m field_schema(\n\u001b[1;32m    623\u001b[0m             f,\n\u001b[1;32m    624\u001b[0m             by_alias\u001b[38;5;241m=\u001b[39mby_alias,\n\u001b[1;32m    625\u001b[0m             model_name_map\u001b[38;5;241m=\u001b[39mmodel_name_map,\n\u001b[1;32m    626\u001b[0m             ref_prefix\u001b[38;5;241m=\u001b[39mref_prefix,\n\u001b[1;32m    627\u001b[0m             ref_template\u001b[38;5;241m=\u001b[39mref_template,\n\u001b[1;32m    628\u001b[0m             known_models\u001b[38;5;241m=\u001b[39mknown_models,\n\u001b[1;32m    629\u001b[0m         )\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m SkipField \u001b[38;5;28;01mas\u001b[39;00m skip:\n\u001b[1;32m    631\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(skip\u001b[38;5;241m.\u001b[39mmessage, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pydantic/v1/schema.py:255\u001b[0m, in \u001b[0;36mfield_schema\u001b[0;34m(field, by_alias, model_name_map, ref_prefix, ref_template, known_models)\u001b[0m\n\u001b[1;32m    252\u001b[0m     s\u001b[38;5;241m.\u001b[39mupdate(validation_schema)\n\u001b[1;32m    253\u001b[0m     schema_overrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m f_schema, f_definitions, f_nested_models \u001b[38;5;241m=\u001b[39m field_type_schema(\n\u001b[1;32m    256\u001b[0m     field,\n\u001b[1;32m    257\u001b[0m     by_alias\u001b[38;5;241m=\u001b[39mby_alias,\n\u001b[1;32m    258\u001b[0m     model_name_map\u001b[38;5;241m=\u001b[39mmodel_name_map,\n\u001b[1;32m    259\u001b[0m     schema_overrides\u001b[38;5;241m=\u001b[39mschema_overrides,\n\u001b[1;32m    260\u001b[0m     ref_prefix\u001b[38;5;241m=\u001b[39mref_prefix,\n\u001b[1;32m    261\u001b[0m     ref_template\u001b[38;5;241m=\u001b[39mref_template,\n\u001b[1;32m    262\u001b[0m     known_models\u001b[38;5;241m=\u001b[39mknown_models \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mset\u001b[39m(),\n\u001b[1;32m    263\u001b[0m )\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# $ref will only be returned when there are no schema_overrides\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$ref\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m f_schema:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pydantic/v1/schema.py:527\u001b[0m, in \u001b[0;36mfield_type_schema\u001b[0;34m(field, by_alias, model_name_map, ref_template, schema_overrides, ref_prefix, known_models)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m field\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01min\u001b[39;00m {SHAPE_SINGLETON, SHAPE_GENERIC}, field\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 527\u001b[0m     f_schema, f_definitions, f_nested_models \u001b[38;5;241m=\u001b[39m field_singleton_schema(\n\u001b[1;32m    528\u001b[0m         field,\n\u001b[1;32m    529\u001b[0m         by_alias\u001b[38;5;241m=\u001b[39mby_alias,\n\u001b[1;32m    530\u001b[0m         model_name_map\u001b[38;5;241m=\u001b[39mmodel_name_map,\n\u001b[1;32m    531\u001b[0m         schema_overrides\u001b[38;5;241m=\u001b[39mschema_overrides,\n\u001b[1;32m    532\u001b[0m         ref_prefix\u001b[38;5;241m=\u001b[39mref_prefix,\n\u001b[1;32m    533\u001b[0m         ref_template\u001b[38;5;241m=\u001b[39mref_template,\n\u001b[1;32m    534\u001b[0m         known_models\u001b[38;5;241m=\u001b[39mknown_models,\n\u001b[1;32m    535\u001b[0m     )\n\u001b[1;32m    536\u001b[0m     definitions\u001b[38;5;241m.\u001b[39mupdate(f_definitions)\n\u001b[1;32m    537\u001b[0m     nested_models\u001b[38;5;241m.\u001b[39mupdate(f_nested_models)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pydantic/v1/schema.py:852\u001b[0m, in \u001b[0;36mfield_singleton_schema\u001b[0;34m(field, by_alias, model_name_map, ref_template, schema_overrides, ref_prefix, known_models)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;66;03m# Recurse into this field if it contains sub_fields and is NOT a\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;66;03m# BaseModel OR that BaseModel is a const\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m field\u001b[38;5;241m.\u001b[39msub_fields \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    850\u001b[0m     (field\u001b[38;5;241m.\u001b[39mfield_info \u001b[38;5;129;01mand\u001b[39;00m field\u001b[38;5;241m.\u001b[39mfield_info\u001b[38;5;241m.\u001b[39mconst) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lenient_issubclass(field_type, BaseModel)\n\u001b[1;32m    851\u001b[0m ):\n\u001b[0;32m--> 852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m field_singleton_sub_fields_schema(\n\u001b[1;32m    853\u001b[0m         field,\n\u001b[1;32m    854\u001b[0m         by_alias\u001b[38;5;241m=\u001b[39mby_alias,\n\u001b[1;32m    855\u001b[0m         model_name_map\u001b[38;5;241m=\u001b[39mmodel_name_map,\n\u001b[1;32m    856\u001b[0m         schema_overrides\u001b[38;5;241m=\u001b[39mschema_overrides,\n\u001b[1;32m    857\u001b[0m         ref_prefix\u001b[38;5;241m=\u001b[39mref_prefix,\n\u001b[1;32m    858\u001b[0m         ref_template\u001b[38;5;241m=\u001b[39mref_template,\n\u001b[1;32m    859\u001b[0m         known_models\u001b[38;5;241m=\u001b[39mknown_models,\n\u001b[1;32m    860\u001b[0m     )\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m field_type \u001b[38;5;129;01mis\u001b[39;00m Any \u001b[38;5;129;01mor\u001b[39;00m field_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m field_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m==\u001b[39m TypeVar \u001b[38;5;129;01mor\u001b[39;00m get_origin(field_type) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m:\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, definitions, nested_models  \u001b[38;5;66;03m# no restrictions\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pydantic/v1/schema.py:747\u001b[0m, in \u001b[0;36mfield_singleton_sub_fields_schema\u001b[0;34m(field, by_alias, model_name_map, ref_template, schema_overrides, ref_prefix, known_models)\u001b[0m\n\u001b[1;32m    745\u001b[0m sub_field_schemas \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sf \u001b[38;5;129;01min\u001b[39;00m sub_fields:\n\u001b[0;32m--> 747\u001b[0m     sub_schema, sub_definitions, sub_nested_models \u001b[38;5;241m=\u001b[39m field_type_schema(\n\u001b[1;32m    748\u001b[0m         sf,\n\u001b[1;32m    749\u001b[0m         by_alias\u001b[38;5;241m=\u001b[39mby_alias,\n\u001b[1;32m    750\u001b[0m         model_name_map\u001b[38;5;241m=\u001b[39mmodel_name_map,\n\u001b[1;32m    751\u001b[0m         schema_overrides\u001b[38;5;241m=\u001b[39mschema_overrides,\n\u001b[1;32m    752\u001b[0m         ref_prefix\u001b[38;5;241m=\u001b[39mref_prefix,\n\u001b[1;32m    753\u001b[0m         ref_template\u001b[38;5;241m=\u001b[39mref_template,\n\u001b[1;32m    754\u001b[0m         known_models\u001b[38;5;241m=\u001b[39mknown_models,\n\u001b[1;32m    755\u001b[0m     )\n\u001b[1;32m    756\u001b[0m     definitions\u001b[38;5;241m.\u001b[39mupdate(sub_definitions)\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m schema_overrides \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallOf\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sub_schema:\n\u001b[1;32m    758\u001b[0m         \u001b[38;5;66;03m# if the sub_field is a referenced schema we only need the referenced\u001b[39;00m\n\u001b[1;32m    759\u001b[0m         \u001b[38;5;66;03m# object. Otherwise we will end up with several allOf inside anyOf/oneOf.\u001b[39;00m\n\u001b[1;32m    760\u001b[0m         \u001b[38;5;66;03m# See https://github.com/pydantic/pydantic/issues/1209\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pydantic/v1/schema.py:462\u001b[0m, in \u001b[0;36mfield_type_schema\u001b[0;34m(field, by_alias, model_name_map, ref_template, schema_overrides, ref_prefix, known_models)\u001b[0m\n\u001b[1;32m    452\u001b[0m f_schema: Dict[\u001b[38;5;28mstr\u001b[39m, Any]\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m field\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    454\u001b[0m     SHAPE_LIST,\n\u001b[1;32m    455\u001b[0m     SHAPE_TUPLE_ELLIPSIS,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    460\u001b[0m     SHAPE_DEQUE,\n\u001b[1;32m    461\u001b[0m }:\n\u001b[0;32m--> 462\u001b[0m     items_schema, f_definitions, f_nested_models \u001b[38;5;241m=\u001b[39m field_singleton_schema(\n\u001b[1;32m    463\u001b[0m         field,\n\u001b[1;32m    464\u001b[0m         by_alias\u001b[38;5;241m=\u001b[39mby_alias,\n\u001b[1;32m    465\u001b[0m         model_name_map\u001b[38;5;241m=\u001b[39mmodel_name_map,\n\u001b[1;32m    466\u001b[0m         ref_prefix\u001b[38;5;241m=\u001b[39mref_prefix,\n\u001b[1;32m    467\u001b[0m         ref_template\u001b[38;5;241m=\u001b[39mref_template,\n\u001b[1;32m    468\u001b[0m         known_models\u001b[38;5;241m=\u001b[39mknown_models,\n\u001b[1;32m    469\u001b[0m     )\n\u001b[1;32m    470\u001b[0m     definitions\u001b[38;5;241m.\u001b[39mupdate(f_definitions)\n\u001b[1;32m    471\u001b[0m     nested_models\u001b[38;5;241m.\u001b[39mupdate(f_nested_models)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pydantic/v1/schema.py:852\u001b[0m, in \u001b[0;36mfield_singleton_schema\u001b[0;34m(field, by_alias, model_name_map, ref_template, schema_overrides, ref_prefix, known_models)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;66;03m# Recurse into this field if it contains sub_fields and is NOT a\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;66;03m# BaseModel OR that BaseModel is a const\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m field\u001b[38;5;241m.\u001b[39msub_fields \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    850\u001b[0m     (field\u001b[38;5;241m.\u001b[39mfield_info \u001b[38;5;129;01mand\u001b[39;00m field\u001b[38;5;241m.\u001b[39mfield_info\u001b[38;5;241m.\u001b[39mconst) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lenient_issubclass(field_type, BaseModel)\n\u001b[1;32m    851\u001b[0m ):\n\u001b[0;32m--> 852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m field_singleton_sub_fields_schema(\n\u001b[1;32m    853\u001b[0m         field,\n\u001b[1;32m    854\u001b[0m         by_alias\u001b[38;5;241m=\u001b[39mby_alias,\n\u001b[1;32m    855\u001b[0m         model_name_map\u001b[38;5;241m=\u001b[39mmodel_name_map,\n\u001b[1;32m    856\u001b[0m         schema_overrides\u001b[38;5;241m=\u001b[39mschema_overrides,\n\u001b[1;32m    857\u001b[0m         ref_prefix\u001b[38;5;241m=\u001b[39mref_prefix,\n\u001b[1;32m    858\u001b[0m         ref_template\u001b[38;5;241m=\u001b[39mref_template,\n\u001b[1;32m    859\u001b[0m         known_models\u001b[38;5;241m=\u001b[39mknown_models,\n\u001b[1;32m    860\u001b[0m     )\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m field_type \u001b[38;5;129;01mis\u001b[39;00m Any \u001b[38;5;129;01mor\u001b[39;00m field_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m field_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m==\u001b[39m TypeVar \u001b[38;5;129;01mor\u001b[39;00m get_origin(field_type) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m:\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, definitions, nested_models  \u001b[38;5;66;03m# no restrictions\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pydantic/v1/schema.py:701\u001b[0m, in \u001b[0;36mfield_singleton_sub_fields_schema\u001b[0;34m(field, by_alias, model_name_map, ref_template, schema_overrides, ref_prefix, known_models)\u001b[0m\n\u001b[1;32m    699\u001b[0m nested_models: Set[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sub_fields) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m field_type_schema(\n\u001b[1;32m    702\u001b[0m         sub_fields[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    703\u001b[0m         by_alias\u001b[38;5;241m=\u001b[39mby_alias,\n\u001b[1;32m    704\u001b[0m         model_name_map\u001b[38;5;241m=\u001b[39mmodel_name_map,\n\u001b[1;32m    705\u001b[0m         schema_overrides\u001b[38;5;241m=\u001b[39mschema_overrides,\n\u001b[1;32m    706\u001b[0m         ref_prefix\u001b[38;5;241m=\u001b[39mref_prefix,\n\u001b[1;32m    707\u001b[0m         ref_template\u001b[38;5;241m=\u001b[39mref_template,\n\u001b[1;32m    708\u001b[0m         known_models\u001b[38;5;241m=\u001b[39mknown_models,\n\u001b[1;32m    709\u001b[0m     )\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    711\u001b[0m     s: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pydantic/v1/schema.py:527\u001b[0m, in \u001b[0;36mfield_type_schema\u001b[0;34m(field, by_alias, model_name_map, ref_template, schema_overrides, ref_prefix, known_models)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m field\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01min\u001b[39;00m {SHAPE_SINGLETON, SHAPE_GENERIC}, field\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 527\u001b[0m     f_schema, f_definitions, f_nested_models \u001b[38;5;241m=\u001b[39m field_singleton_schema(\n\u001b[1;32m    528\u001b[0m         field,\n\u001b[1;32m    529\u001b[0m         by_alias\u001b[38;5;241m=\u001b[39mby_alias,\n\u001b[1;32m    530\u001b[0m         model_name_map\u001b[38;5;241m=\u001b[39mmodel_name_map,\n\u001b[1;32m    531\u001b[0m         schema_overrides\u001b[38;5;241m=\u001b[39mschema_overrides,\n\u001b[1;32m    532\u001b[0m         ref_prefix\u001b[38;5;241m=\u001b[39mref_prefix,\n\u001b[1;32m    533\u001b[0m         ref_template\u001b[38;5;241m=\u001b[39mref_template,\n\u001b[1;32m    534\u001b[0m         known_models\u001b[38;5;241m=\u001b[39mknown_models,\n\u001b[1;32m    535\u001b[0m     )\n\u001b[1;32m    536\u001b[0m     definitions\u001b[38;5;241m.\u001b[39mupdate(f_definitions)\n\u001b[1;32m    537\u001b[0m     nested_models\u001b[38;5;241m.\u001b[39mupdate(f_nested_models)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pydantic/v1/schema.py:951\u001b[0m, in \u001b[0;36mfield_singleton_schema\u001b[0;34m(field, by_alias, model_name_map, ref_template, schema_overrides, ref_prefix, known_models)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m Generic \u001b[38;5;129;01min\u001b[39;00m field_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__bases__\u001b[39m:\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f_schema, definitions, nested_models\n\u001b[0;32m--> 951\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValue not declarable with JSON Schema, field: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfield\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Value not declarable with JSON Schema, field: name='_callbacks_List[langchain_core.callbacks.base.BaseCallbackHandler]' type=BaseCallbackHandler required=True"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import functools\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "\n",
    "# research_agent = create_agent(llm, [tavily_tool], \"You are a web researcher.\")\n",
    "# research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
    "\n",
    "# # NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION. PROCEED WITH CAUTION\n",
    "# code_agent = create_agent(\n",
    "#     llm,\n",
    "#     [python_repl_tool],\n",
    "#     \"You may generate safe python code to analyze data and generate charts using matplotlib.\",\n",
    "# )\n",
    "# code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
    "\n",
    "\n",
    "# RAG_agent = create_agent(\n",
    "#     llm,\n",
    "#     [RAG],\n",
    "#     \"Use this tools when questions are related to Japan or of Sports category.\",\n",
    "# )\n",
    "# rag_node = functools.partial(agent_node, agent=RAG_agent, name=\"RAG\")\n",
    "\n",
    "# workflow = StateGraph(AgentState)\n",
    "# workflow.add_node(\"Researcher\", research_node)\n",
    "# workflow.add_node(\"Coder\", code_node)\n",
    "# workflow.add_node(\"RAG\", rag_node)\n",
    "# workflow.add_node(\"supervisor\", supervisor_chain)\n",
    "\n",
    "#######################################################################\n",
    "\n",
    "# research_agent = create_react_agent(llm, tools=[tavily_tool])\n",
    "# research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
    "\n",
    "# # NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION. PROCEED WITH CAUTION\n",
    "# code_agent = create_react_agent(llm, tools=[python_repl_tool])\n",
    "# code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Remaining tooooooooooooooooooooooooooooooooooooooooooooooooollllllllllllllllllls\n",
    "# @tool\n",
    "# def multiply(first_number: int, second_number: int):\n",
    "#     \"\"\"Multiplies two numbers together.\"\"\"\n",
    "#     return first_number * second_number\n",
    "\n",
    "# model_with_tools = model.bind(tools=[convert_to_openai_tool(move_to_object_tool),convert_to_openai_tool(grasp_object_tool),convert_to_openai_tool(hold_object_tool),convert_to_openai_tool(connect_tool)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# robot1_agent= create_agent(llm, \n",
    "#                                  [convert_to_openai_tool(move_to_object_tool),convert_to_openai_tool(grasp_object_tool),convert_to_openai_tool(hold_object_tool),convert_to_openai_tool(connect_tool)],\n",
    "#                                 'Use this tools when task is supposed to be done by Robot1_base_holder')\n",
    "\n",
    "robot1_agent = create_agent(\n",
    "    llm,\n",
    "    [\n",
    "        convert_to_openai_tool(MoveToObjectTool()),  # Ensure proper instantiation\n",
    "        convert_to_openai_tool(GraspObjectTool()),\n",
    "        convert_to_openai_tool(HoldObjectTool()),\n",
    "        convert_to_openai_tool(ConnectTool()),\n",
    "    ],\n",
    "    'Use these tools when the task is supposed to be done by Robot1_base_holder'\n",
    ")\n",
    "\n",
    "robot1_node = functools.partial(agent_node, agent=robot1_agent, name=\"Robot1_base_holder\")\n",
    "\n",
    "\n",
    "# robot2_agent = create_agent(llm,\n",
    "#                                   [convert_to_openai_tool(move_to_object_tool),convert_to_openai_tool(grasp_object_tool),convert_to_openai_tool(hold_object_tool),convert_to_openai_tool(connect_tool)],\n",
    "#                                  'Use this tools when task is supposed to be done by Robot2_assembler')\n",
    "\n",
    "\n",
    "\n",
    "robot2_agent = create_agent(\n",
    "    llm,\n",
    "    [\n",
    "        convert_to_openai_tool(MoveToObjectTool()),  # Ensure proper instantiation\n",
    "        convert_to_openai_tool(GraspObjectTool()),\n",
    "        convert_to_openai_tool(HoldObjectTool()),\n",
    "        convert_to_openai_tool(ConnectTool()),\n",
    "    ],\n",
    "    'Use this tools when task is supposed to be done by Robot2_assembler'\n",
    ")\n",
    "robot2_node = functools.partial(agent_node, agent=robot2_agent, name=\"Robot2_assembler\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7ed994-2584-49a9-8b54-4479634ef652",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# workflow = Graph()\n",
    "\n",
    "# workflow.add_node(\"Agent\", function_1)\n",
    "# workflow.add_node(\"tool\", function_2)\n",
    "\n",
    "# workflow.add_edge('Agent', 'tool')\n",
    "\n",
    "# workflow.set_entry_point(\"Agent\")\n",
    "# workflow.set_finish_point(\"tool\")\n",
    "\n",
    "# app = workflow.compile()\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "\n",
    "workflow.add_node(\"generate_plan1\", generate_plan_step1)\n",
    "workflow.add_node(\"generate_plan2\", generate_plan_step2)\n",
    "workflow.add_edge('generate_plan1', 'generate_plan2')\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)\n",
    "workflow.add_node(\"Robot1_base_holder\", robot1_node)\n",
    "workflow.add_node(\"Robot2_assembler\", robot2_node)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for member in members:\n",
    "    # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "# Finally, add entrypoint\n",
    "workflow.set_entry_point(\"generate_plan1\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a45303-17c0-4983-83b1-666373bac7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"assemble a gripper of one base and two parts for me\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f9a9a1-1969-42df-9895-28eb9ed998fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad50720-1789-4995-a897-c852385dca3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645c8dd9-1080-42bf-8aab-f6afce2a5daf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a3e72-6c70-4fc2-b1d0-fb0428de6159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f56078-7bfc-46ef-98ce-2ef6e18ddbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc95a33-0c61-4f01-9a8c-2517cd00aa15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5e5469-42a5-402b-8e55-f24fb88ef0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9363f558-872c-46d3-8009-7b913544771c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795906f-1410-4dc2-b9b7-2b06e9079418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef60e3a-0cdd-4db2-ac69-bb3c9166fad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
